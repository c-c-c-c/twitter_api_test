{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/11_topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.19</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# debug\n",
    "#%pdb on\n",
    "\n",
    "import pixiedust #%pixie_debugger\n",
    "\n",
    "# tfがエラーはかないため\n",
    "# tfがエラーはかないため\n",
    "#import tensorflow as tf\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "df = pd.read_csv(\"../result0605.csv\", engine='python')\n",
    "\n",
    "type(df[\"description\"])\n",
    "docs = df[\"description\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RhY0Iq0ycIv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93794\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM4WRXtQgL9G"
   },
   "source": [
    "### Neologdを使ってtokenizeする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1LVnUt6FgYbW"
   },
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "import MeCab\n",
    "\n",
    "def make_neologd_tagger():\n",
    "    cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
    "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
    "                               shell=True).communicate()[0]).decode('utf-8')\n",
    "    m=MeCab.Tagger(\"-Ochasen -d \"+str(path_neologd))\n",
    "    return (m)\n",
    "\n",
    "\n",
    "def neolog_prep_text( text, m):\n",
    "    return_words = []\n",
    "\n",
    "    \n",
    "    splited_text = (re.split('[\\t,]', line) for line in m.parse(text).split('\\n'))\n",
    "    for tmp_word in splited_text :\n",
    "        if (tmp_word[0] in ('EOS', '', 't', 'ー') ):\n",
    "           continue \n",
    "        if not re.match( '名詞' ,tmp_word[3]  ) or tmp_word[0] in emoji.UNICODE_EMOJI[\"en\"]:\n",
    "            continue\n",
    "        else:\n",
    "            return_words.append(tmp_word[0])\n",
    "\n",
    "    return return_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPvZBojxgYcW"
   },
   "source": [
    "* tokenizationの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1iICBt6EgqC-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93794/93794 [00:24<00:00, 3778.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "m = make_neologd_tagger()\n",
    "\n",
    "new_docs = list()\n",
    "for doc in tqdm(docs):\n",
    "  if str(doc) == \"nan\":\n",
    "    continue\n",
    "  tmp_words =  neolog_prep_text(str(doc), m)\n",
    "  new_docs.append( tmp_words )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBDnVSoZgaMJ"
   },
   "source": [
    "* tokenizationの結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p6MVn-YGhBst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['過去', 'ジャパリカート', '動画', 'TSUMURI', 'KART', 'VRChat', 'ワリスノ', 'MK', '8', 'DX', '一位', 'りし', 'た人', '社会', '出て', '配信', 'https', 'co', 'FJoitl', '8', 'JHE', 'ヘッダ', '猫', '飼い主', 'smmmmm']\n"
     ]
    }
   ],
   "source": [
    "print(new_docs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7lABQFJgdBj"
   },
   "source": [
    "* 各文書を長い文字列で表しなおす（CountVectorizerを後で使うため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mnNRbzLzi6vh"
   },
   "outputs": [],
   "source": [
    "corpus = [' '.join(doc) for doc in new_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nu0eT7OXCzD"
   },
   "source": [
    "## 11-02 データ行列の作成\n",
    "* LDAの場合、単に単語の出現頻度を重みとして各文書をベクトル化する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo8oPlaMCzoM"
   },
   "source": [
    "### sklearnのCountVectorizerで疎行列化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pyLBUfSXTUL"
   },
   "source": [
    "* 全文書の半分より多い文書に現れる単語は、高頻度語とみなして削除する。\n",
    "* 30件未満の文書にしか現れない単語は、低頻度語とみなして削除する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "def download_stopwords(path):\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    if os.path.exists(path):\n",
    "        print('File already exists.')\n",
    "    else:\n",
    "        print('Downloading...')\n",
    "        # Download the file from `url` and save it locally under `file_name`:\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "\n",
    "def create_stopwords(file_path):\n",
    "    stop_words = []\n",
    "    for w in open(path, \"r\"):\n",
    "        w = w.replace('\\n','')\n",
    "        if len(w) > 0:\n",
    "          stop_words.append(w)\n",
    "    return stop_words    \n",
    "\n",
    "path = \"stop_words.txt\"\n",
    "download_stopwords(path)\n",
    "stop_words = create_stopwords(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zrj0mmMrCzNI"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "MIN_DF = 30\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.5, min_df= MIN_DF, stop_words=stop_words)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XoE0bBHJEFEj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2wVko9vXnlq"
   },
   "source": [
    "* 文書数と語彙サイズを変数にセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kAd821DGFXXp"
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG8puM9OXrNk"
   },
   "source": [
    "### TF-IDFで各文書における単語の重みを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ywX2HtW-Elar"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "Xtfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hdac5_tSE4YC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4227)\t0.603862693464167\n",
      "  (0, 4148)\t0.4706802938434637\n",
      "  (0, 3490)\t0.1847556021921528\n",
      "  (0, 3414)\t0.3341859275888348\n",
      "  (0, 3402)\t0.3582132311126841\n",
      "  (0, 1747)\t0.24047370992039763\n",
      "  (0, 1109)\t0.2860956441170824\n"
     ]
    }
   ],
   "source": [
    "print(Xtfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CY0mRZonFEJF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88481, 5100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXUdhYDMYuDO"
   },
   "source": [
    "### LDAのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5L34qQ1iFncJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from time import time\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPHsNjupYp7w"
   },
   "source": [
    "### トピックの重要語を取り出す関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rpoC-pofHMEO"
   },
   "outputs": [],
   "source": [
    "def get_top_words(model, feature_names, n_top_words=30):\n",
    "  top_features = list()\n",
    "  weights = list()\n",
    "  for topic_idx, topic in enumerate(model.components_):\n",
    "    top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    top_features.append([feature_names[i] for i in top_features_ind])\n",
    "    weights.append(topic[top_features_ind])\n",
    "  return top_features, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EHfuc6RZgPh"
   },
   "source": [
    "# LDAでトピック抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSAEThMwZjhb"
   },
   "source": [
    "### LDAによるトピック抽出の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NFf5jcX5b45d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_word_cloud(n_components, lda):\n",
    "    # matplotlib and seaborn for plotting\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    plt.style.use('dark_background')\n",
    "    top_words, weights = get_top_words(lda, vectorizer.get_feature_names())\n",
    "    topic_words = [dict(zip(top_words[i], weights[i])) for i in range(n_components)]\n",
    "    FONT_PATH = \"/usr/share/fonts/opentype/ipaexfont-mincho/ipaexm.ttf\"\n",
    "    cloud = WordCloud(stopwords=STOPWORDS,\n",
    "                  font_path=FONT_PATH,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=100,\n",
    "                  colormap='tab10'\n",
    "                  )\n",
    "\n",
    "    tate = math.ceil(len(topic_words) / 2)\n",
    "    fig, axes = plt.subplots(tate, 2, figsize=(32, 50), sharex=True, sharey=True)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "\n",
    "        if i >= len(topic_words):\n",
    "            break\n",
    "\n",
    "        fig.add_subplot(ax)\n",
    "        cloud.generate_from_frequencies(topic_words[i], max_font_size=500)\n",
    "        plt.gca().imshow(cloud)\n",
    "        plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "        plt.gca().axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pdf = PdfPages( \n",
    "        (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M') + 'topic.pdf')\n",
    "\n",
    "\n",
    "    fignums = plt.get_fignums()\n",
    "    for fignum in fignums:\n",
    "        plt.figure(fignum)\n",
    "        pdf.savefig()\n",
    "\n",
    "    pdf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KuuSTK6fZfu7"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "def lda_main (batch_size ,n_components, topic_word_prior,doc_topic_prior  ,max_iter=30):\n",
    "\n",
    "    folder_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M')\n",
    "\n",
    "    # フォルダを作成\n",
    "    os.mkdir(\"./0701expt_para/\"+folder_name)\n",
    "    os.chdir(\"./0701expt_para/\"+folder_name)\n",
    "\n",
    "    # logging\n",
    "    logger = logging.getLogger()\n",
    "    fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.setLevel(logging.WARNING)\n",
    "    \n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=n_components, \n",
    "                                    max_iter=max_iter,\n",
    "                                    topic_word_prior=topic_word_prior, # トピック数の逆数が目安の0.01,0.02,0.05,0.1などなど試す\n",
    "                                    doc_topic_prior =  doc_topic_prior, \n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50,\n",
    "                                    batch_size= batch_size,# 多くする\n",
    "                                    learning_decay = 1.3,    \n",
    "                                    mean_change_tol=1e-4,\n",
    "                                    random_state=1,\n",
    "                                    evaluate_every=1,\n",
    "                                    verbose=1)\n",
    "    print((f\"Fitting LDA models with tf features, \"\n",
    "    f\"n_samples={n_samples} and n_features={n_features}\"))\n",
    "    t0 = time()\n",
    "    lda.fit(X)\n",
    "    print(f\"done in {time() - t0:0.3f}s.\")\n",
    "    # パラメータの比較はperplexity\n",
    "    # ハイパーパラメータ調整を頑張る！（やってられない！といわない！！）\n",
    "    \n",
    "    \n",
    "    coherance = metric_coherence_gensim(measure='c_v', \n",
    "#                         top_n=20, # これはデフォルトが20\n",
    "                        topic_word_distrib=lda.components_, \n",
    "                        dtm=Xtfidf,  # tfidfの結果\n",
    "                        vocab=np.array([x for x in vectorizer.vocabulary_.keys()]), \n",
    "                        texts=new_docs)\n",
    "    \n",
    "    \n",
    "    results = {\n",
    "            \"perplexity\" : lda.perplexity(X) ,\n",
    "            \"coherance\": coherance,\n",
    "        }\n",
    "\n",
    "    logger.warning('MIN_DF:{0}'.format(MIN_DF) )\n",
    "    logger.warning('params:batch_size:{0}'.format(batch_size)) \n",
    "    logger.warning('params:n_components:{0}'.format(n_components)) \n",
    "    logger.warning('params:topic_word_prior:{0}'.format(topic_word_prior)) \n",
    "    logger.warning('params:doc_topic_prior:{0}'.format(doc_topic_prior)) \n",
    "    logger.warning('params:max_iter:{0}'.format(max_iter)) \n",
    "    logger.warning('done n_iter:{0}'.format(lda.n_iter_)) \n",
    "    logger.warning('perplexity:{0}'.format(results[\"perplexity\"])) \n",
    "    logger.warning('coherance:{0}'.format(results[\"coherance\"]) )\n",
    "    logger.warning('check all params:{0}'.format(lda.get_params() )) \n",
    "    make_word_cloud(n_components, lda)\n",
    "    # pickle\n",
    "    file_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M') + '_lda.pickle'\n",
    "    with open(file_name, mode=\"wb\") as f:\n",
    "        pickle.dump(lda, f)\n",
    "    \n",
    "#     breakpoint()\n",
    "    \n",
    "    os.chdir(\"../../\")\n",
    "    return(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWd3DND8aAVz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2442.6483\n",
      "iteration: 2 of max_iter: 50, perplexity: 2305.9873\n",
      "iteration: 3 of max_iter: 50, perplexity: 2240.0972\n",
      "iteration: 4 of max_iter: 50, perplexity: 2199.9365\n",
      "iteration: 5 of max_iter: 50, perplexity: 2173.8301\n",
      "iteration: 6 of max_iter: 50, perplexity: 2154.9585\n",
      "iteration: 7 of max_iter: 50, perplexity: 2141.0314\n",
      "iteration: 8 of max_iter: 50, perplexity: 2129.9832\n",
      "iteration: 9 of max_iter: 50, perplexity: 2120.3882\n",
      "iteration: 10 of max_iter: 50, perplexity: 2112.6026\n",
      "iteration: 11 of max_iter: 50, perplexity: 2106.1410\n",
      "iteration: 12 of max_iter: 50, perplexity: 2100.0842\n",
      "iteration: 13 of max_iter: 50, perplexity: 2094.8928\n",
      "iteration: 14 of max_iter: 50, perplexity: 2090.6150\n",
      "iteration: 15 of max_iter: 50, perplexity: 2086.2783\n",
      "iteration: 16 of max_iter: 50, perplexity: 2082.4369\n",
      "iteration: 17 of max_iter: 50, perplexity: 2079.0850\n",
      "iteration: 18 of max_iter: 50, perplexity: 2075.8503\n",
      "iteration: 19 of max_iter: 50, perplexity: 2072.9818\n",
      "iteration: 20 of max_iter: 50, perplexity: 2070.2641\n",
      "iteration: 21 of max_iter: 50, perplexity: 2067.7896\n",
      "iteration: 22 of max_iter: 50, perplexity: 2065.5018\n",
      "iteration: 23 of max_iter: 50, perplexity: 2063.2158\n",
      "iteration: 24 of max_iter: 50, perplexity: 2061.4086\n",
      "iteration: 25 of max_iter: 50, perplexity: 2059.7933\n",
      "iteration: 26 of max_iter: 50, perplexity: 2057.8165\n",
      "iteration: 27 of max_iter: 50, perplexity: 2055.9918\n",
      "iteration: 28 of max_iter: 50, perplexity: 2054.6164\n",
      "iteration: 29 of max_iter: 50, perplexity: 2053.3480\n",
      "iteration: 30 of max_iter: 50, perplexity: 2051.9422\n",
      "iteration: 31 of max_iter: 50, perplexity: 2050.6976\n",
      "iteration: 32 of max_iter: 50, perplexity: 2049.4851\n",
      "iteration: 33 of max_iter: 50, perplexity: 2048.1899\n",
      "iteration: 34 of max_iter: 50, perplexity: 2046.9292\n",
      "iteration: 35 of max_iter: 50, perplexity: 2045.7561\n",
      "iteration: 36 of max_iter: 50, perplexity: 2044.6900\n",
      "iteration: 37 of max_iter: 50, perplexity: 2043.6042\n",
      "iteration: 38 of max_iter: 50, perplexity: 2042.5170\n",
      "iteration: 39 of max_iter: 50, perplexity: 2041.4687\n",
      "iteration: 40 of max_iter: 50, perplexity: 2040.6587\n",
      "iteration: 41 of max_iter: 50, perplexity: 2039.6896\n",
      "iteration: 42 of max_iter: 50, perplexity: 2038.7560\n",
      "iteration: 43 of max_iter: 50, perplexity: 2037.9163\n",
      "iteration: 44 of max_iter: 50, perplexity: 2037.0466\n",
      "iteration: 45 of max_iter: 50, perplexity: 2036.3367\n",
      "iteration: 46 of max_iter: 50, perplexity: 2035.6374\n",
      "iteration: 47 of max_iter: 50, perplexity: 2034.7649\n",
      "iteration: 48 of max_iter: 50, perplexity: 2034.1312\n",
      "iteration: 49 of max_iter: 50, perplexity: 2033.5304\n",
      "iteration: 50 of max_iter: 50, perplexity: 2032.7929\n",
      "done in 2154.899s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2518.0873\n",
      "iteration: 2 of max_iter: 50, perplexity: 2373.3360\n",
      "iteration: 3 of max_iter: 50, perplexity: 2298.4009\n",
      "iteration: 4 of max_iter: 50, perplexity: 2251.3746\n",
      "iteration: 5 of max_iter: 50, perplexity: 2218.4179\n",
      "iteration: 6 of max_iter: 50, perplexity: 2194.6874\n",
      "iteration: 7 of max_iter: 50, perplexity: 2176.2436\n",
      "iteration: 8 of max_iter: 50, perplexity: 2161.4808\n",
      "iteration: 9 of max_iter: 50, perplexity: 2149.2310\n",
      "iteration: 10 of max_iter: 50, perplexity: 2138.8443\n",
      "iteration: 11 of max_iter: 50, perplexity: 2129.7817\n",
      "iteration: 12 of max_iter: 50, perplexity: 2122.1729\n",
      "iteration: 13 of max_iter: 50, perplexity: 2115.0911\n",
      "iteration: 14 of max_iter: 50, perplexity: 2109.1741\n",
      "iteration: 15 of max_iter: 50, perplexity: 2103.6964\n",
      "iteration: 16 of max_iter: 50, perplexity: 2098.6482\n",
      "iteration: 17 of max_iter: 50, perplexity: 2094.1114\n",
      "iteration: 18 of max_iter: 50, perplexity: 2090.1326\n",
      "iteration: 19 of max_iter: 50, perplexity: 2086.4679\n",
      "iteration: 20 of max_iter: 50, perplexity: 2082.8810\n",
      "iteration: 21 of max_iter: 50, perplexity: 2079.5728\n",
      "iteration: 22 of max_iter: 50, perplexity: 2076.4180\n",
      "iteration: 23 of max_iter: 50, perplexity: 2073.5924\n",
      "iteration: 24 of max_iter: 50, perplexity: 2070.9189\n",
      "iteration: 25 of max_iter: 50, perplexity: 2068.2926\n",
      "iteration: 26 of max_iter: 50, perplexity: 2065.9706\n",
      "iteration: 27 of max_iter: 50, perplexity: 2063.7479\n",
      "iteration: 28 of max_iter: 50, perplexity: 2061.7188\n",
      "iteration: 29 of max_iter: 50, perplexity: 2059.6690\n",
      "iteration: 30 of max_iter: 50, perplexity: 2057.7296\n",
      "iteration: 31 of max_iter: 50, perplexity: 2055.8473\n",
      "iteration: 32 of max_iter: 50, perplexity: 2053.9789\n",
      "iteration: 33 of max_iter: 50, perplexity: 2052.2066\n",
      "iteration: 34 of max_iter: 50, perplexity: 2050.6332\n",
      "iteration: 35 of max_iter: 50, perplexity: 2048.9699\n",
      "iteration: 36 of max_iter: 50, perplexity: 2047.4856\n",
      "iteration: 37 of max_iter: 50, perplexity: 2046.1545\n",
      "iteration: 38 of max_iter: 50, perplexity: 2044.7258\n",
      "iteration: 39 of max_iter: 50, perplexity: 2043.3242\n",
      "iteration: 40 of max_iter: 50, perplexity: 2042.0317\n",
      "iteration: 41 of max_iter: 50, perplexity: 2040.7072\n",
      "iteration: 42 of max_iter: 50, perplexity: 2039.4616\n",
      "iteration: 43 of max_iter: 50, perplexity: 2038.3639\n",
      "iteration: 44 of max_iter: 50, perplexity: 2037.3163\n",
      "iteration: 45 of max_iter: 50, perplexity: 2036.2394\n",
      "iteration: 46 of max_iter: 50, perplexity: 2035.1194\n",
      "iteration: 47 of max_iter: 50, perplexity: 2034.1373\n",
      "iteration: 48 of max_iter: 50, perplexity: 2033.0945\n",
      "iteration: 49 of max_iter: 50, perplexity: 2032.1437\n",
      "iteration: 50 of max_iter: 50, perplexity: 2031.2484\n",
      "done in 2175.362s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2600.5726\n",
      "iteration: 2 of max_iter: 50, perplexity: 2421.2650\n",
      "iteration: 3 of max_iter: 50, perplexity: 2341.3527\n",
      "iteration: 4 of max_iter: 50, perplexity: 2293.4119\n",
      "iteration: 5 of max_iter: 50, perplexity: 2260.6766\n",
      "iteration: 6 of max_iter: 50, perplexity: 2236.6677\n",
      "iteration: 7 of max_iter: 50, perplexity: 2217.9483\n",
      "iteration: 8 of max_iter: 50, perplexity: 2202.5674\n",
      "iteration: 9 of max_iter: 50, perplexity: 2189.6019\n",
      "iteration: 10 of max_iter: 50, perplexity: 2178.7720\n",
      "iteration: 11 of max_iter: 50, perplexity: 2169.0401\n",
      "iteration: 12 of max_iter: 50, perplexity: 2160.7517\n",
      "iteration: 13 of max_iter: 50, perplexity: 2153.4432\n",
      "iteration: 14 of max_iter: 50, perplexity: 2146.8812\n",
      "iteration: 15 of max_iter: 50, perplexity: 2140.9464\n",
      "iteration: 19 of max_iter: 50, perplexity: 2122.4499\n",
      "iteration: 20 of max_iter: 50, perplexity: 2118.5894\n",
      "iteration: 21 of max_iter: 50, perplexity: 2115.1153\n",
      "iteration: 22 of max_iter: 50, perplexity: 2111.8130\n",
      "iteration: 23 of max_iter: 50, perplexity: 2108.6459\n",
      "iteration: 24 of max_iter: 50, perplexity: 2105.7827\n",
      "iteration: 25 of max_iter: 50, perplexity: 2103.0446\n",
      "iteration: 26 of max_iter: 50, perplexity: 2100.4738\n",
      "iteration: 27 of max_iter: 50, perplexity: 2098.0588\n",
      "iteration: 28 of max_iter: 50, perplexity: 2095.8803\n",
      "iteration: 29 of max_iter: 50, perplexity: 2093.7334\n",
      "iteration: 30 of max_iter: 50, perplexity: 2091.7335\n",
      "iteration: 31 of max_iter: 50, perplexity: 2089.7568\n",
      "iteration: 32 of max_iter: 50, perplexity: 2087.8132\n",
      "iteration: 33 of max_iter: 50, perplexity: 2086.0202\n",
      "iteration: 34 of max_iter: 50, perplexity: 2084.3589\n",
      "iteration: 35 of max_iter: 50, perplexity: 2082.7675\n",
      "iteration: 36 of max_iter: 50, perplexity: 2081.1684\n",
      "iteration: 37 of max_iter: 50, perplexity: 2079.7280\n",
      "iteration: 38 of max_iter: 50, perplexity: 2078.2556\n",
      "iteration: 39 of max_iter: 50, perplexity: 2076.9234\n",
      "iteration: 40 of max_iter: 50, perplexity: 2075.5906\n",
      "iteration: 41 of max_iter: 50, perplexity: 2074.2870\n",
      "iteration: 42 of max_iter: 50, perplexity: 2073.0242\n",
      "iteration: 43 of max_iter: 50, perplexity: 2071.8993\n",
      "iteration: 44 of max_iter: 50, perplexity: 2070.8045\n",
      "iteration: 45 of max_iter: 50, perplexity: 2069.5927\n",
      "iteration: 46 of max_iter: 50, perplexity: 2068.4488\n",
      "iteration: 47 of max_iter: 50, perplexity: 2067.4342\n",
      "iteration: 48 of max_iter: 50, perplexity: 2066.3470\n",
      "iteration: 49 of max_iter: 50, perplexity: 2065.3943\n",
      "iteration: 50 of max_iter: 50, perplexity: 2064.5077\n",
      "done in 2190.208s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 3019.4488\n",
      "iteration: 2 of max_iter: 50, perplexity: 2817.5409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 50, perplexity: 2717.0257\n",
      "iteration: 4 of max_iter: 50, perplexity: 2653.5488\n",
      "iteration: 8 of max_iter: 50, perplexity: 2528.3555\n",
      "iteration: 9 of max_iter: 50, perplexity: 2510.7499\n",
      "iteration: 10 of max_iter: 50, perplexity: 2495.7991\n",
      "iteration: 11 of max_iter: 50, perplexity: 2482.8400\n",
      "iteration: 12 of max_iter: 50, perplexity: 2471.5344\n",
      "iteration: 13 of max_iter: 50, perplexity: 2461.5655\n",
      "iteration: 14 of max_iter: 50, perplexity: 2452.6397\n",
      "iteration: 15 of max_iter: 50, perplexity: 2444.6273\n",
      "iteration: 16 of max_iter: 50, perplexity: 2437.3322\n",
      "iteration: 17 of max_iter: 50, perplexity: 2430.7038\n",
      "iteration: 18 of max_iter: 50, perplexity: 2424.6480\n",
      "iteration: 19 of max_iter: 50, perplexity: 2419.0730\n",
      "iteration: 20 of max_iter: 50, perplexity: 2413.8646\n",
      "iteration: 21 of max_iter: 50, perplexity: 2409.0185\n",
      "iteration: 22 of max_iter: 50, perplexity: 2404.5498\n",
      "iteration: 23 of max_iter: 50, perplexity: 2400.3941\n",
      "iteration: 24 of max_iter: 50, perplexity: 2396.4382\n",
      "iteration: 25 of max_iter: 50, perplexity: 2392.7364\n",
      "iteration: 26 of max_iter: 50, perplexity: 2389.2206\n",
      "iteration: 27 of max_iter: 50, perplexity: 2385.9307\n",
      "iteration: 28 of max_iter: 50, perplexity: 2382.8821\n",
      "iteration: 29 of max_iter: 50, perplexity: 2379.9289\n",
      "iteration: 30 of max_iter: 50, perplexity: 2377.1144\n",
      "iteration: 31 of max_iter: 50, perplexity: 2374.4084\n",
      "iteration: 32 of max_iter: 50, perplexity: 2371.8298\n",
      "iteration: 33 of max_iter: 50, perplexity: 2369.3754\n",
      "iteration: 34 of max_iter: 50, perplexity: 2367.0239\n",
      "iteration: 35 of max_iter: 50, perplexity: 2364.7799\n",
      "iteration: 36 of max_iter: 50, perplexity: 2362.6109\n",
      "iteration: 37 of max_iter: 50, perplexity: 2360.5272\n",
      "iteration: 38 of max_iter: 50, perplexity: 2358.5291\n",
      "iteration: 39 of max_iter: 50, perplexity: 2356.5934\n",
      "iteration: 40 of max_iter: 50, perplexity: 2354.7728\n",
      "iteration: 41 of max_iter: 50, perplexity: 2352.9745\n",
      "iteration: 42 of max_iter: 50, perplexity: 2351.2520\n",
      "iteration: 46 of max_iter: 50, perplexity: 2344.9421\n",
      "iteration: 47 of max_iter: 50, perplexity: 2343.4812\n",
      "iteration: 48 of max_iter: 50, perplexity: 2342.0654\n",
      "iteration: 49 of max_iter: 50, perplexity: 2340.7045\n",
      "iteration: 50 of max_iter: 50, perplexity: 2339.3426\n",
      "done in 2413.953s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 3458.6439\n",
      "iteration: 2 of max_iter: 50, perplexity: 3183.7229\n",
      "iteration: 3 of max_iter: 50, perplexity: 3045.7744\n",
      "iteration: 4 of max_iter: 50, perplexity: 2959.8552\n",
      "iteration: 5 of max_iter: 50, perplexity: 2900.0997\n",
      "iteration: 6 of max_iter: 50, perplexity: 2855.6569\n",
      "iteration: 7 of max_iter: 50, perplexity: 2821.0361\n",
      "iteration: 8 of max_iter: 50, perplexity: 2793.1303\n",
      "iteration: 9 of max_iter: 50, perplexity: 2770.0470\n",
      "iteration: 10 of max_iter: 50, perplexity: 2750.5408\n",
      "iteration: 11 of max_iter: 50, perplexity: 2733.7789\n",
      "iteration: 12 of max_iter: 50, perplexity: 2719.1741\n",
      "iteration: 13 of max_iter: 50, perplexity: 2706.2902\n",
      "iteration: 14 of max_iter: 50, perplexity: 2694.8187\n",
      "iteration: 15 of max_iter: 50, perplexity: 2684.5136\n",
      "iteration: 16 of max_iter: 50, perplexity: 2675.1904\n",
      "iteration: 17 of max_iter: 50, perplexity: 2666.6996\n",
      "iteration: 18 of max_iter: 50, perplexity: 2658.9267\n",
      "iteration: 19 of max_iter: 50, perplexity: 2651.7800\n",
      "iteration: 20 of max_iter: 50, perplexity: 2645.1694\n",
      "iteration: 21 of max_iter: 50, perplexity: 2639.0341\n",
      "iteration: 22 of max_iter: 50, perplexity: 2633.3103\n",
      "iteration: 23 of max_iter: 50, perplexity: 2627.9598\n",
      "iteration: 24 of max_iter: 50, perplexity: 2622.9462\n",
      "iteration: 25 of max_iter: 50, perplexity: 2618.2263\n",
      "iteration: 26 of max_iter: 50, perplexity: 2613.7818\n",
      "iteration: 27 of max_iter: 50, perplexity: 2609.5831\n",
      "iteration: 28 of max_iter: 50, perplexity: 2605.6051\n",
      "iteration: 29 of max_iter: 50, perplexity: 2601.8289\n",
      "iteration: 30 of max_iter: 50, perplexity: 2598.2371\n",
      "iteration: 31 of max_iter: 50, perplexity: 2594.8239\n",
      "iteration: 32 of max_iter: 50, perplexity: 2591.5618\n",
      "iteration: 33 of max_iter: 50, perplexity: 2588.4481\n",
      "iteration: 34 of max_iter: 50, perplexity: 2585.4683\n",
      "iteration: 35 of max_iter: 50, perplexity: 2582.6178\n",
      "iteration: 36 of max_iter: 50, perplexity: 2579.8808\n",
      "iteration: 37 of max_iter: 50, perplexity: 2577.2548\n",
      "iteration: 38 of max_iter: 50, perplexity: 2574.7324\n",
      "iteration: 39 of max_iter: 50, perplexity: 2572.3027\n",
      "iteration: 40 of max_iter: 50, perplexity: 2569.9630\n",
      "iteration: 41 of max_iter: 50, perplexity: 2567.7070\n",
      "iteration: 42 of max_iter: 50, perplexity: 2565.5295\n",
      "iteration: 43 of max_iter: 50, perplexity: 2563.4258\n",
      "iteration: 44 of max_iter: 50, perplexity: 2561.3935\n",
      "iteration: 45 of max_iter: 50, perplexity: 2559.4249\n",
      "iteration: 46 of max_iter: 50, perplexity: 2557.5203\n",
      "iteration: 47 of max_iter: 50, perplexity: 2555.6749\n",
      "iteration: 48 of max_iter: 50, perplexity: 2553.8861\n",
      "iteration: 49 of max_iter: 50, perplexity: 2552.1509\n",
      "iteration: 50 of max_iter: 50, perplexity: 2550.4667\n",
      "done in 3039.859s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 3 of max_iter: 50, perplexity: 3077.8576\n",
      "iteration: 4 of max_iter: 50, perplexity: 2976.6873\n",
      "iteration: 5 of max_iter: 50, perplexity: 2907.3292\n",
      "iteration: 6 of max_iter: 50, perplexity: 2856.0147\n",
      "iteration: 7 of max_iter: 50, perplexity: 2816.0750\n",
      "iteration: 8 of max_iter: 50, perplexity: 2783.8544\n",
      "iteration: 9 of max_iter: 50, perplexity: 2757.1614\n",
      "iteration: 10 of max_iter: 50, perplexity: 2734.5848\n",
      "iteration: 11 of max_iter: 50, perplexity: 2715.1695\n",
      "iteration: 12 of max_iter: 50, perplexity: 2698.2429\n",
      "iteration: 13 of max_iter: 50, perplexity: 2683.3164\n",
      "iteration: 14 of max_iter: 50, perplexity: 2670.0252\n",
      "iteration: 15 of max_iter: 50, perplexity: 2658.0913\n",
      "iteration: 16 of max_iter: 50, perplexity: 2647.2982\n",
      "iteration: 17 of max_iter: 50, perplexity: 2637.4747\n",
      "iteration: 18 of max_iter: 50, perplexity: 2628.4836\n",
      "iteration: 19 of max_iter: 50, perplexity: 2620.2130\n",
      "iteration: 20 of max_iter: 50, perplexity: 2612.5713\n",
      "iteration: 21 of max_iter: 50, perplexity: 2605.4823\n",
      "iteration: 22 of max_iter: 50, perplexity: 2598.8821\n",
      "iteration: 23 of max_iter: 50, perplexity: 2592.7166\n",
      "iteration: 24 of max_iter: 50, perplexity: 2586.9398\n",
      "iteration: 25 of max_iter: 50, perplexity: 2581.5121\n",
      "iteration: 26 of max_iter: 50, perplexity: 2576.3995\n",
      "iteration: 27 of max_iter: 50, perplexity: 2571.5725\n",
      "iteration: 28 of max_iter: 50, perplexity: 2567.0050\n",
      "iteration: 29 of max_iter: 50, perplexity: 2562.6745\n",
      "iteration: 30 of max_iter: 50, perplexity: 2558.5610\n",
      "iteration: 31 of max_iter: 50, perplexity: 2554.6466\n",
      "iteration: 32 of max_iter: 50, perplexity: 2550.9157\n",
      "iteration: 33 of max_iter: 50, perplexity: 2547.3543\n",
      "iteration: 34 of max_iter: 50, perplexity: 2543.9497\n",
      "iteration: 37 of max_iter: 50, perplexity: 2534.5690\n",
      "iteration: 38 of max_iter: 50, perplexity: 2531.6890\n",
      "iteration: 39 of max_iter: 50, perplexity: 2528.9190\n",
      "iteration: 40 of max_iter: 50, perplexity: 2526.2523\n",
      "iteration: 41 of max_iter: 50, perplexity: 2523.6823\n",
      "iteration: 42 of max_iter: 50, perplexity: 2521.2033\n",
      "iteration: 43 of max_iter: 50, perplexity: 2518.8100\n",
      "iteration: 44 of max_iter: 50, perplexity: 2516.4975\n",
      "iteration: 45 of max_iter: 50, perplexity: 2514.2612\n",
      "iteration: 46 of max_iter: 50, perplexity: 2512.0970\n",
      "iteration: 47 of max_iter: 50, perplexity: 2510.0010\n",
      "iteration: 48 of max_iter: 50, perplexity: 2507.9697\n",
      "iteration: 49 of max_iter: 50, perplexity: 2505.9998\n",
      "iteration: 50 of max_iter: 50, perplexity: 2504.0881\n",
      "done in 2678.985s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 3690.8049\n",
      "iteration: 2 of max_iter: 50, perplexity: 3313.4320\n",
      "iteration: 3 of max_iter: 50, perplexity: 3147.9983\n",
      "iteration: 4 of max_iter: 50, perplexity: 3049.2957\n",
      "iteration: 5 of max_iter: 50, perplexity: 2981.8630\n",
      "iteration: 6 of max_iter: 50, perplexity: 2932.0753\n",
      "iteration: 7 of max_iter: 50, perplexity: 2893.3965\n",
      "iteration: 8 of max_iter: 50, perplexity: 2862.2416\n",
      "iteration: 9 of max_iter: 50, perplexity: 2836.4582\n",
      "iteration: 10 of max_iter: 50, perplexity: 2814.6657\n",
      "iteration: 11 of max_iter: 50, perplexity: 2795.9328\n",
      "iteration: 12 of max_iter: 50, perplexity: 2779.6057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 13 of max_iter: 50, perplexity: 2765.2103\n",
      "iteration: 14 of max_iter: 50, perplexity: 2752.3933\n",
      "iteration: 15 of max_iter: 50, perplexity: 2740.8855\n",
      "iteration: 16 of max_iter: 50, perplexity: 2730.4778\n",
      "iteration: 17 of max_iter: 50, perplexity: 2721.0048\n",
      "iteration: 20 of max_iter: 50, perplexity: 2696.9872\n",
      "iteration: 21 of max_iter: 50, perplexity: 2690.1493\n",
      "iteration: 22 of max_iter: 50, perplexity: 2683.7821\n",
      "iteration: 23 of max_iter: 50, perplexity: 2677.8336\n",
      "iteration: 24 of max_iter: 50, perplexity: 2672.2596\n",
      "iteration: 25 of max_iter: 50, perplexity: 2667.0218\n",
      "iteration: 26 of max_iter: 50, perplexity: 2662.0876\n",
      "iteration: 27 of max_iter: 50, perplexity: 2657.4282\n",
      "iteration: 28 of max_iter: 50, perplexity: 2653.0190\n",
      "iteration: 29 of max_iter: 50, perplexity: 2648.8379\n",
      "iteration: 30 of max_iter: 50, perplexity: 2644.8658\n",
      "iteration: 31 of max_iter: 50, perplexity: 2641.0855\n",
      "iteration: 32 of max_iter: 50, perplexity: 2637.4820\n",
      "iteration: 33 of max_iter: 50, perplexity: 2634.0416\n",
      "iteration: 34 of max_iter: 50, perplexity: 2630.7522\n",
      "iteration: 35 of max_iter: 50, perplexity: 2627.6030\n",
      "iteration: 36 of max_iter: 50, perplexity: 2624.5841\n",
      "iteration: 37 of max_iter: 50, perplexity: 2621.6867\n",
      "iteration: 38 of max_iter: 50, perplexity: 2618.9026\n",
      "iteration: 39 of max_iter: 50, perplexity: 2616.2245\n",
      "iteration: 40 of max_iter: 50, perplexity: 2613.6459\n",
      "iteration: 41 of max_iter: 50, perplexity: 2611.1605\n",
      "iteration: 42 of max_iter: 50, perplexity: 2608.7627\n",
      "iteration: 43 of max_iter: 50, perplexity: 2606.4476\n",
      "iteration: 44 of max_iter: 50, perplexity: 2604.2102\n",
      "iteration: 45 of max_iter: 50, perplexity: 2602.0464\n",
      "iteration: 46 of max_iter: 50, perplexity: 2599.9520\n",
      "iteration: 47 of max_iter: 50, perplexity: 2597.9234\n",
      "iteration: 48 of max_iter: 50, perplexity: 2595.9571\n",
      "iteration: 49 of max_iter: 50, perplexity: 2594.0500\n",
      "iteration: 50 of max_iter: 50, perplexity: 2592.1990\n",
      "done in 2641.372s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 4 of max_iter: 50, perplexity: 2042.2478\n",
      "iteration: 5 of max_iter: 50, perplexity: 2018.2285\n",
      "iteration: 6 of max_iter: 50, perplexity: 2000.9186\n",
      "iteration: 7 of max_iter: 50, perplexity: 1988.1417\n",
      "iteration: 8 of max_iter: 50, perplexity: 1977.8632\n",
      "iteration: 9 of max_iter: 50, perplexity: 1969.1716\n",
      "iteration: 10 of max_iter: 50, perplexity: 1961.8837\n",
      "iteration: 11 of max_iter: 50, perplexity: 1956.0656\n",
      "iteration: 12 of max_iter: 50, perplexity: 1950.6448\n",
      "iteration: 13 of max_iter: 50, perplexity: 1946.0292\n",
      "iteration: 14 of max_iter: 50, perplexity: 1941.7523\n",
      "iteration: 15 of max_iter: 50, perplexity: 1937.9330\n",
      "iteration: 16 of max_iter: 50, perplexity: 1934.3954\n",
      "iteration: 17 of max_iter: 50, perplexity: 1931.2156\n",
      "iteration: 18 of max_iter: 50, perplexity: 1928.3735\n",
      "iteration: 19 of max_iter: 50, perplexity: 1925.6935\n",
      "iteration: 20 of max_iter: 50, perplexity: 1923.2567\n",
      "iteration: 21 of max_iter: 50, perplexity: 1920.8584\n",
      "iteration: 22 of max_iter: 50, perplexity: 1918.9638\n",
      "iteration: 23 of max_iter: 50, perplexity: 1916.8100\n",
      "iteration: 24 of max_iter: 50, perplexity: 1915.0001\n",
      "iteration: 25 of max_iter: 50, perplexity: 1913.4723\n",
      "iteration: 26 of max_iter: 50, perplexity: 1911.8684\n",
      "iteration: 27 of max_iter: 50, perplexity: 1910.1778\n",
      "iteration: 28 of max_iter: 50, perplexity: 1908.8480\n",
      "iteration: 29 of max_iter: 50, perplexity: 1907.5660\n",
      "iteration: 30 of max_iter: 50, perplexity: 1906.3938\n",
      "iteration: 31 of max_iter: 50, perplexity: 1905.2084\n",
      "iteration: 32 of max_iter: 50, perplexity: 1904.1135\n",
      "iteration: 33 of max_iter: 50, perplexity: 1902.9433\n",
      "iteration: 34 of max_iter: 50, perplexity: 1901.9081\n",
      "iteration: 35 of max_iter: 50, perplexity: 1900.7293\n",
      "iteration: 36 of max_iter: 50, perplexity: 1899.8024\n",
      "iteration: 37 of max_iter: 50, perplexity: 1898.8307\n",
      "iteration: 38 of max_iter: 50, perplexity: 1897.7349\n",
      "iteration: 39 of max_iter: 50, perplexity: 1896.9528\n",
      "iteration: 40 of max_iter: 50, perplexity: 1896.1955\n",
      "iteration: 41 of max_iter: 50, perplexity: 1895.1566\n",
      "iteration: 42 of max_iter: 50, perplexity: 1894.4380\n",
      "iteration: 43 of max_iter: 50, perplexity: 1893.7400\n",
      "iteration: 44 of max_iter: 50, perplexity: 1892.8703\n",
      "iteration: 45 of max_iter: 50, perplexity: 1892.1618\n",
      "iteration: 46 of max_iter: 50, perplexity: 1891.4465\n",
      "iteration: 47 of max_iter: 50, perplexity: 1890.8379\n",
      "iteration: 48 of max_iter: 50, perplexity: 1890.1561\n",
      "iteration: 49 of max_iter: 50, perplexity: 1889.5102\n",
      "iteration: 50 of max_iter: 50, perplexity: 1888.9353\n",
      "done in 2178.033s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2336.3872\n",
      "iteration: 2 of max_iter: 50, perplexity: 2202.4218\n",
      "iteration: 3 of max_iter: 50, perplexity: 2133.5838\n",
      "iteration: 4 of max_iter: 50, perplexity: 2090.1466\n",
      "iteration: 5 of max_iter: 50, perplexity: 2059.8258\n",
      "iteration: 6 of max_iter: 50, perplexity: 2037.7587\n",
      "iteration: 7 of max_iter: 50, perplexity: 2020.8045\n",
      "iteration: 8 of max_iter: 50, perplexity: 2007.3876\n",
      "iteration: 9 of max_iter: 50, perplexity: 1996.1397\n",
      "iteration: 10 of max_iter: 50, perplexity: 1986.4823\n",
      "iteration: 11 of max_iter: 50, perplexity: 1978.3043\n",
      "iteration: 12 of max_iter: 50, perplexity: 1971.2646\n",
      "iteration: 13 of max_iter: 50, perplexity: 1964.8899\n",
      "iteration: 14 of max_iter: 50, perplexity: 1959.2576\n",
      "iteration: 15 of max_iter: 50, perplexity: 1954.2695\n",
      "iteration: 16 of max_iter: 50, perplexity: 1949.7474\n",
      "iteration: 17 of max_iter: 50, perplexity: 1945.6560\n",
      "iteration: 18 of max_iter: 50, perplexity: 1941.9235\n",
      "iteration: 19 of max_iter: 50, perplexity: 1938.3857\n",
      "iteration: 20 of max_iter: 50, perplexity: 1935.2056\n",
      "iteration: 21 of max_iter: 50, perplexity: 1932.1877\n",
      "iteration: 22 of max_iter: 50, perplexity: 1929.2767\n",
      "iteration: 23 of max_iter: 50, perplexity: 1926.6352\n",
      "iteration: 24 of max_iter: 50, perplexity: 1924.1168\n",
      "iteration: 25 of max_iter: 50, perplexity: 1921.8453\n",
      "iteration: 26 of max_iter: 50, perplexity: 1919.7504\n",
      "iteration: 27 of max_iter: 50, perplexity: 1917.7196\n",
      "iteration: 28 of max_iter: 50, perplexity: 1915.7965\n",
      "iteration: 29 of max_iter: 50, perplexity: 1913.9456\n",
      "iteration: 30 of max_iter: 50, perplexity: 1912.1631\n",
      "iteration: 31 of max_iter: 50, perplexity: 1910.4549\n",
      "iteration: 32 of max_iter: 50, perplexity: 1908.7428\n",
      "iteration: 33 of max_iter: 50, perplexity: 1907.2476\n",
      "iteration: 36 of max_iter: 50, perplexity: 1902.9038\n",
      "iteration: 37 of max_iter: 50, perplexity: 1901.5347\n",
      "iteration: 38 of max_iter: 50, perplexity: 1900.2722\n",
      "iteration: 39 of max_iter: 50, perplexity: 1899.0718\n",
      "iteration: 40 of max_iter: 50, perplexity: 1897.7912\n",
      "iteration: 41 of max_iter: 50, perplexity: 1896.6093\n",
      "iteration: 42 of max_iter: 50, perplexity: 1895.4943\n",
      "iteration: 43 of max_iter: 50, perplexity: 1894.4525\n",
      "iteration: 44 of max_iter: 50, perplexity: 1893.5194\n",
      "iteration: 45 of max_iter: 50, perplexity: 1892.5534\n",
      "iteration: 46 of max_iter: 50, perplexity: 1891.6046\n",
      "iteration: 47 of max_iter: 50, perplexity: 1890.6594\n",
      "iteration: 48 of max_iter: 50, perplexity: 1889.7721\n",
      "iteration: 49 of max_iter: 50, perplexity: 1888.8541\n",
      "iteration: 50 of max_iter: 50, perplexity: 1888.0381\n",
      "done in 2167.611s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2412.9786\n",
      "iteration: 2 of max_iter: 50, perplexity: 2247.0446\n",
      "iteration: 3 of max_iter: 50, perplexity: 2173.2958\n",
      "iteration: 4 of max_iter: 50, perplexity: 2128.9707\n",
      "iteration: 5 of max_iter: 50, perplexity: 2099.0189\n",
      "iteration: 6 of max_iter: 50, perplexity: 2076.9259\n",
      "iteration: 7 of max_iter: 50, perplexity: 2059.5879\n",
      "iteration: 8 of max_iter: 50, perplexity: 2045.3640\n",
      "iteration: 9 of max_iter: 50, perplexity: 2033.5880\n",
      "iteration: 10 of max_iter: 50, perplexity: 2023.5509\n",
      "iteration: 11 of max_iter: 50, perplexity: 2014.6718\n",
      "iteration: 12 of max_iter: 50, perplexity: 2007.1089\n",
      "iteration: 13 of max_iter: 50, perplexity: 2000.2551\n",
      "iteration: 14 of max_iter: 50, perplexity: 1994.3620\n",
      "iteration: 15 of max_iter: 50, perplexity: 1988.9254\n",
      "iteration: 16 of max_iter: 50, perplexity: 1984.0593\n",
      "iteration: 17 of max_iter: 50, perplexity: 1979.5553\n",
      "iteration: 18 of max_iter: 50, perplexity: 1975.4970\n",
      "iteration: 19 of max_iter: 50, perplexity: 1971.7825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 20 of max_iter: 50, perplexity: 1968.3124\n",
      "iteration: 21 of max_iter: 50, perplexity: 1965.0881\n",
      "iteration: 22 of max_iter: 50, perplexity: 1961.9338\n",
      "iteration: 23 of max_iter: 50, perplexity: 1959.1380\n",
      "iteration: 26 of max_iter: 50, perplexity: 1951.6114\n",
      "iteration: 27 of max_iter: 50, perplexity: 1949.4342\n",
      "iteration: 28 of max_iter: 50, perplexity: 1947.3545\n",
      "iteration: 29 of max_iter: 50, perplexity: 1945.3935\n",
      "iteration: 30 of max_iter: 50, perplexity: 1943.4491\n",
      "iteration: 31 of max_iter: 50, perplexity: 1941.6956\n",
      "iteration: 32 of max_iter: 50, perplexity: 1939.9425\n",
      "iteration: 33 of max_iter: 50, perplexity: 1938.3281\n",
      "iteration: 34 of max_iter: 50, perplexity: 1936.7851\n",
      "iteration: 35 of max_iter: 50, perplexity: 1935.3383\n",
      "iteration: 36 of max_iter: 50, perplexity: 1933.9535\n",
      "iteration: 37 of max_iter: 50, perplexity: 1932.6660\n",
      "iteration: 38 of max_iter: 50, perplexity: 1931.2801\n",
      "iteration: 39 of max_iter: 50, perplexity: 1929.9781\n",
      "iteration: 40 of max_iter: 50, perplexity: 1928.7522\n",
      "iteration: 41 of max_iter: 50, perplexity: 1927.5140\n",
      "iteration: 42 of max_iter: 50, perplexity: 1926.4614\n",
      "iteration: 43 of max_iter: 50, perplexity: 1925.3413\n",
      "iteration: 44 of max_iter: 50, perplexity: 1924.2754\n",
      "iteration: 45 of max_iter: 50, perplexity: 1923.2617\n",
      "iteration: 46 of max_iter: 50, perplexity: 1922.2245\n",
      "iteration: 47 of max_iter: 50, perplexity: 1921.2301\n",
      "iteration: 48 of max_iter: 50, perplexity: 1920.3395\n",
      "iteration: 49 of max_iter: 50, perplexity: 1919.4161\n",
      "iteration: 50 of max_iter: 50, perplexity: 1918.5528\n",
      "done in 2192.347s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2801.6195\n",
      "iteration: 2 of max_iter: 50, perplexity: 2614.9891\n",
      "iteration: 3 of max_iter: 50, perplexity: 2522.2421\n",
      "iteration: 4 of max_iter: 50, perplexity: 2463.7826\n",
      "iteration: 5 of max_iter: 50, perplexity: 2422.7401\n",
      "iteration: 6 of max_iter: 50, perplexity: 2392.0081\n",
      "iteration: 7 of max_iter: 50, perplexity: 2367.9392\n",
      "iteration: 8 of max_iter: 50, perplexity: 2348.4379\n",
      "iteration: 9 of max_iter: 50, perplexity: 2332.2331\n",
      "iteration: 10 of max_iter: 50, perplexity: 2318.4675\n",
      "iteration: 11 of max_iter: 50, perplexity: 2306.5097\n",
      "iteration: 12 of max_iter: 50, perplexity: 2296.1331\n",
      "iteration: 15 of max_iter: 50, perplexity: 2271.4055\n",
      "iteration: 16 of max_iter: 50, perplexity: 2264.7164\n",
      "iteration: 17 of max_iter: 50, perplexity: 2258.6436\n",
      "iteration: 18 of max_iter: 50, perplexity: 2253.0868\n",
      "iteration: 19 of max_iter: 50, perplexity: 2247.9458\n",
      "iteration: 20 of max_iter: 50, perplexity: 2243.1722\n",
      "iteration: 21 of max_iter: 50, perplexity: 2238.7577\n",
      "iteration: 22 of max_iter: 50, perplexity: 2234.6305\n",
      "iteration: 23 of max_iter: 50, perplexity: 2230.7963\n",
      "iteration: 24 of max_iter: 50, perplexity: 2227.1504\n",
      "iteration: 25 of max_iter: 50, perplexity: 2223.7519\n",
      "iteration: 26 of max_iter: 50, perplexity: 2220.5488\n",
      "iteration: 27 of max_iter: 50, perplexity: 2217.5412\n",
      "iteration: 28 of max_iter: 50, perplexity: 2214.6823\n",
      "iteration: 29 of max_iter: 50, perplexity: 2211.9999\n",
      "iteration: 30 of max_iter: 50, perplexity: 2209.4412\n",
      "iteration: 31 of max_iter: 50, perplexity: 2206.9666\n",
      "iteration: 32 of max_iter: 50, perplexity: 2204.6040\n",
      "iteration: 33 of max_iter: 50, perplexity: 2202.3582\n",
      "iteration: 34 of max_iter: 50, perplexity: 2200.1832\n",
      "iteration: 35 of max_iter: 50, perplexity: 2198.1148\n",
      "iteration: 36 of max_iter: 50, perplexity: 2196.1520\n",
      "iteration: 37 of max_iter: 50, perplexity: 2194.2587\n",
      "iteration: 38 of max_iter: 50, perplexity: 2192.4359\n",
      "iteration: 39 of max_iter: 50, perplexity: 2190.6705\n",
      "iteration: 40 of max_iter: 50, perplexity: 2188.9606\n",
      "iteration: 41 of max_iter: 50, perplexity: 2187.3472\n",
      "iteration: 42 of max_iter: 50, perplexity: 2185.7816\n",
      "iteration: 43 of max_iter: 50, perplexity: 2184.2804\n",
      "iteration: 44 of max_iter: 50, perplexity: 2182.8139\n",
      "iteration: 45 of max_iter: 50, perplexity: 2181.3939\n",
      "iteration: 46 of max_iter: 50, perplexity: 2180.0064\n",
      "iteration: 47 of max_iter: 50, perplexity: 2178.6441\n",
      "iteration: 48 of max_iter: 50, perplexity: 2177.3660\n",
      "iteration: 49 of max_iter: 50, perplexity: 2176.0906\n",
      "iteration: 50 of max_iter: 50, perplexity: 2174.8781\n",
      "done in 2320.790s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 2 of max_iter: 50, perplexity: 2955.1496\n",
      "iteration: 3 of max_iter: 50, perplexity: 2827.6867\n",
      "iteration: 4 of max_iter: 50, perplexity: 2748.3486\n",
      "iteration: 5 of max_iter: 50, perplexity: 2693.2238\n",
      "iteration: 6 of max_iter: 50, perplexity: 2652.2413\n",
      "iteration: 7 of max_iter: 50, perplexity: 2620.3373\n",
      "iteration: 8 of max_iter: 50, perplexity: 2594.6248\n",
      "iteration: 9 of max_iter: 50, perplexity: 2573.3686\n",
      "iteration: 10 of max_iter: 50, perplexity: 2555.4122\n",
      "iteration: 11 of max_iter: 50, perplexity: 2539.9884\n",
      "iteration: 12 of max_iter: 50, perplexity: 2526.5482\n",
      "iteration: 13 of max_iter: 50, perplexity: 2514.7029\n",
      "iteration: 14 of max_iter: 50, perplexity: 2504.1521\n",
      "iteration: 15 of max_iter: 50, perplexity: 2494.6738\n",
      "iteration: 16 of max_iter: 50, perplexity: 2486.1088\n",
      "iteration: 17 of max_iter: 50, perplexity: 2478.3073\n",
      "iteration: 18 of max_iter: 50, perplexity: 2471.1643\n",
      "iteration: 19 of max_iter: 50, perplexity: 2464.6005\n",
      "iteration: 20 of max_iter: 50, perplexity: 2458.5258\n",
      "iteration: 21 of max_iter: 50, perplexity: 2452.8866\n",
      "iteration: 22 of max_iter: 50, perplexity: 2447.6303\n",
      "iteration: 23 of max_iter: 50, perplexity: 2442.7161\n",
      "iteration: 24 of max_iter: 50, perplexity: 2438.1096\n",
      "iteration: 25 of max_iter: 50, perplexity: 2433.7784\n",
      "iteration: 26 of max_iter: 50, perplexity: 2429.6986\n",
      "iteration: 27 of max_iter: 50, perplexity: 2425.8484\n",
      "iteration: 28 of max_iter: 50, perplexity: 2422.2014\n",
      "iteration: 29 of max_iter: 50, perplexity: 2418.7340\n",
      "iteration: 30 of max_iter: 50, perplexity: 2415.4422\n",
      "iteration: 31 of max_iter: 50, perplexity: 2412.3079\n",
      "iteration: 32 of max_iter: 50, perplexity: 2409.3160\n",
      "iteration: 33 of max_iter: 50, perplexity: 2406.4615\n",
      "iteration: 34 of max_iter: 50, perplexity: 2403.7278\n",
      "iteration: 35 of max_iter: 50, perplexity: 2401.1130\n",
      "iteration: 36 of max_iter: 50, perplexity: 2398.6064\n",
      "iteration: 37 of max_iter: 50, perplexity: 2396.2004\n",
      "iteration: 38 of max_iter: 50, perplexity: 2393.8840\n",
      "iteration: 39 of max_iter: 50, perplexity: 2391.6550\n",
      "iteration: 40 of max_iter: 50, perplexity: 2389.5086\n"
     ]
    }
   ],
   "source": [
    "for batch_size,n_components, topic_word_prior, doc_topic_prior in itertools.product([3000 ] ,[12,18,24,30,35,40],\n",
    "                                                                                    [0.01, 0.03,0.05, 0.15, 0.3, 0.5, 0.8],[0.01, 0.03,0.05, 0.15, 0.3, 0.5, 0.8] ):\n",
    "\n",
    "    lda_main(n_components=n_components, topic_word_prior=topic_word_prior, doc_topic_prior = doc_topic_prior, batch_size=batch_size, max_iter=50)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pez5Ak2-cUjS"
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_HRjNZJcbNr"
   },
   "source": [
    "### プロフィールを"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_prof (topic_idx, top_n = 100):\n",
    "    \n",
    "    topics = lda.transform(X)\n",
    "    prof_idx_list = topics[:, topic_idx].argsort()[:-top_n - 1:-1]\n",
    "    return [docs[d] for d in prof_idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_top_prof(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nownow_file = (datetime.datetime.now() + datetime.timedelta(hours=9) ).strftime('%m%d_%H%M')+\"topic_modeling.ipynb\"\n",
    "\n",
    "!cp ./topic_modeling.ipynb ./jupyter_backup_for_param/$nownow_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M')+\"_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNyVTNTZxoqrFDwo2+taBP8",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "12MxXsGfePft6pAHKkHrg23Yb7t_RSKiN",
   "name": "11_topic_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
