{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# debug\n",
    "#%pdb on\n",
    "\n",
    "import pixiedust #%pixie_debugger\n",
    "\n",
    "# tfがエラーはかないため\n",
    "# tfがエラーはかないため\n",
    "#import tensorflow as tf\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/kimetsu_tweet_merged.csv\",header=None, names=[\"tweet_id\",\"date\",\"text\",\"like\",\"retweet\",\"author_id\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list_Including_duplication = df.author_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_users = set (user_list_Including_duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[1:1800000].author_id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151278 ./data/kimetsu_tweet_merged.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./data/kimetsu_tweet_merged.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoge = pd.read_csv(\"./data/kimetsu_tweet_merged.csv\", names=[\"tweet_id\",\"date\",\"text\",\"like\",\"retweet\",\"author_id\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397160"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_hoge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like</th>\n",
       "      <th>retweet</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342996412951216129</td>\n",
       "      <td>2020-12-27 09:51:11+09:00</td>\n",
       "      <td>RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...</td>\n",
       "      <td>0</td>\n",
       "      <td>4256</td>\n",
       "      <td>1712148288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1342996368965529600</td>\n",
       "      <td>2020-12-27 09:51:00+09:00</td>\n",
       "      <td>RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...</td>\n",
       "      <td>0</td>\n",
       "      <td>4256</td>\n",
       "      <td>4834371444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1342996354763669505</td>\n",
       "      <td>2020-12-27 09:50:57+09:00</td>\n",
       "      <td>RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...</td>\n",
       "      <td>0</td>\n",
       "      <td>4256</td>\n",
       "      <td>756831577099739136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1342996338577793025</td>\n",
       "      <td>2020-12-27 09:50:53+09:00</td>\n",
       "      <td>RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...</td>\n",
       "      <td>0</td>\n",
       "      <td>4256</td>\n",
       "      <td>117206543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1342996336556183557</td>\n",
       "      <td>2020-12-27 09:50:52+09:00</td>\n",
       "      <td>RT @okap_taro: 春先にメディアと行政が振り撒いたまま放置していた『映画館もヒト...</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>1110572662495952901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146995</th>\n",
       "      <td>1317037363093073921</td>\n",
       "      <td>2020-10-16 18:39:11+09:00</td>\n",
       "      <td>明日鬼滅の刃観てくる～#鬼滅の刃無限列車編</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1124132922817110017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146996</th>\n",
       "      <td>1317037355031687169</td>\n",
       "      <td>2020-10-16 18:39:09+09:00</td>\n",
       "      <td>#鬼滅の刃無限列車編 本日より公開！きめつたまごっち #伊之助いのすけっちカラーも予約開始✨...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1249274731401887746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146997</th>\n",
       "      <td>1317037351537840129</td>\n",
       "      <td>2020-10-16 18:39:08+09:00</td>\n",
       "      <td>#鬼滅の刃無限列車編 #鬼滅の刃 #鬼滅の刃も銀魂も全集中 #鬼滅の刃で1番感動したシーンこ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1252533764984467457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146998</th>\n",
       "      <td>1317037317299736576</td>\n",
       "      <td>2020-10-16 18:39:00+09:00</td>\n",
       "      <td>クライマックスで排気口に放ったプロトン魚雷での大逆転#鬼滅の刃無限列車編</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126720159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146999</th>\n",
       "      <td>1317037311247355905</td>\n",
       "      <td>2020-10-16 18:38:59+09:00</td>\n",
       "      <td>鬼滅の刃観てきた！ストーリーわかってても演技と作画と音楽と全てがほんと素晴らしくてめっちょ泣...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1036999671401480192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id                       date  \\\n",
       "1       1342996412951216129  2020-12-27 09:51:11+09:00   \n",
       "2       1342996368965529600  2020-12-27 09:51:00+09:00   \n",
       "3       1342996354763669505  2020-12-27 09:50:57+09:00   \n",
       "4       1342996338577793025  2020-12-27 09:50:53+09:00   \n",
       "5       1342996336556183557  2020-12-27 09:50:52+09:00   \n",
       "...                     ...                        ...   \n",
       "146995  1317037363093073921  2020-10-16 18:39:11+09:00   \n",
       "146996  1317037355031687169  2020-10-16 18:39:09+09:00   \n",
       "146997  1317037351537840129  2020-10-16 18:39:08+09:00   \n",
       "146998  1317037317299736576  2020-10-16 18:39:00+09:00   \n",
       "146999  1317037311247355905  2020-10-16 18:38:59+09:00   \n",
       "\n",
       "                                                     text like retweet  \\\n",
       "1       RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...    0    4256   \n",
       "2       RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...    0    4256   \n",
       "3       RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...    0    4256   \n",
       "4       RT @rintaro_maro: 歴代興行収入1位記念🎉「鬼滅キャラがジブリの世界に行った...    0    4256   \n",
       "5       RT @okap_taro: 春先にメディアと行政が振り撒いたまま放置していた『映画館もヒト...    0     211   \n",
       "...                                                   ...  ...     ...   \n",
       "146995                              明日鬼滅の刃観てくる～#鬼滅の刃無限列車編    5       0   \n",
       "146996  #鬼滅の刃無限列車編 本日より公開！きめつたまごっち #伊之助いのすけっちカラーも予約開始✨...    0       0   \n",
       "146997  #鬼滅の刃無限列車編 #鬼滅の刃 #鬼滅の刃も銀魂も全集中 #鬼滅の刃で1番感動したシーンこ...    0       1   \n",
       "146998               クライマックスで排気口に放ったプロトン魚雷での大逆転#鬼滅の刃無限列車編    0       0   \n",
       "146999  鬼滅の刃観てきた！ストーリーわかってても演技と作画と音楽と全てがほんと素晴らしくてめっちょ泣...   19       0   \n",
       "\n",
       "                  author_id  \n",
       "1                1712148288  \n",
       "2                4834371444  \n",
       "3        756831577099739136  \n",
       "4                 117206543  \n",
       "5       1110572662495952901  \n",
       "...                     ...  \n",
       "146995  1124132922817110017  \n",
       "146996  1249274731401887746  \n",
       "146997  1252533764984467457  \n",
       "146998            126720159  \n",
       "146999  1036999671401480192  \n",
       "\n",
       "[146999 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hoge[1:147000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = []\n",
    "content =\"\"\n",
    "with open('./data/kimetsu_tweet_merged.csv', mode='r', encoding='utf-8') as f:\n",
    "    for tmp in list(f):\n",
    "        content = tmp.replace('↓', '') \n",
    "        count+=1\n",
    "print(count)\n",
    "f.closed\n",
    "\n",
    "fw = open('./data/kimetsu_tweet_merged_replaced.csv','w')\n",
    "fw.write(content)\n",
    "fw.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/kimetsu_tweet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-926bccfc0b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/kimetsu_tweet.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mall_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mall_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'↓'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/kimetsu_tweet_merged.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/kimetsu_tweet.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./data/kimetsu_tweet.csv', mode='rt', encoding='utf-8') as f:\n",
    "    all_ = f.read()\n",
    "    all_.replace('↓', '')\n",
    "\n",
    "fw = open('./data/kimetsu_tweet_merged.csv','w')\n",
    "fw.write(all_)\n",
    "fw.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-be3c00645c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/kimetsu_tweet_merged_replaced.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/kimetsu_tweet_merged_replaced.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoge[\"text\"].iloc[147325]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hoge[\"text\"].iloc[247330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
