{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/11_topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.19</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# debug\n",
    "#%pdb on\n",
    "\n",
    "import pixiedust #%pixie_debugger\n",
    "\n",
    "# tfがエラーはかないため\n",
    "# tfがエラーはかないため\n",
    "#import tensorflow as tf\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "df = pd.read_csv(\"../data/result0605.csv\", engine='python')\n",
    "\n",
    "type(df[\"description\"])\n",
    "docs = df[\"description\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RhY0Iq0ycIv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93794\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM4WRXtQgL9G"
   },
   "source": [
    "### Neologdを使ってtokenizeする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1LVnUt6FgYbW"
   },
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "import MeCab\n",
    "\n",
    "def make_neologd_tagger():\n",
    "    cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
    "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
    "                               shell=True).communicate()[0]).decode('utf-8')\n",
    "    m=MeCab.Tagger(\"-Ochasen -d \"+str(path_neologd))\n",
    "    return (m)\n",
    "\n",
    "\n",
    "def neolog_prep_text( text, m):\n",
    "    return_words = []\n",
    "\n",
    "    \n",
    "    splited_text = (re.split('[\\t,]', line) for line in m.parse(text).split('\\n'))\n",
    "    for tmp_word in splited_text :\n",
    "        if (tmp_word[0] in ('EOS', '', 't', 'ー') ):\n",
    "           continue \n",
    "        if not re.match( '名詞' ,tmp_word[3]  ) or tmp_word[0] in emoji.UNICODE_EMOJI[\"en\"]:\n",
    "            continue\n",
    "        else:\n",
    "            return_words.append(tmp_word[0])\n",
    "\n",
    "    return return_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPvZBojxgYcW"
   },
   "source": [
    "* tokenizationの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1iICBt6EgqC-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93794/93794 [00:24<00:00, 3903.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "m = make_neologd_tagger()\n",
    "\n",
    "new_docs = list()\n",
    "for doc in tqdm(docs):\n",
    "  if str(doc) == \"nan\":\n",
    "    continue\n",
    "  tmp_words =  neolog_prep_text(str(doc), m)\n",
    "  new_docs.append( tmp_words )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBDnVSoZgaMJ"
   },
   "source": [
    "* tokenizationの結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p6MVn-YGhBst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['過去', 'ジャパリカート', '動画', 'TSUMURI', 'KART', 'VRChat', 'ワリスノ', 'MK', '8', 'DX', '一位', 'りし', 'た人', '社会', '出て', '配信', 'https', 'co', 'FJoitl', '8', 'JHE', 'ヘッダ', '猫', '飼い主', 'smmmmm']\n"
     ]
    }
   ],
   "source": [
    "print(new_docs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7lABQFJgdBj"
   },
   "source": [
    "* 各文書を長い文字列で表しなおす（CountVectorizerを後で使うため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mnNRbzLzi6vh"
   },
   "outputs": [],
   "source": [
    "corpus = [' '.join(doc) for doc in new_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nu0eT7OXCzD"
   },
   "source": [
    "## 11-02 データ行列の作成\n",
    "* LDAの場合、単に単語の出現頻度を重みとして各文書をベクトル化する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo8oPlaMCzoM"
   },
   "source": [
    "### sklearnのCountVectorizerで疎行列化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pyLBUfSXTUL"
   },
   "source": [
    "* 全文書の半分より多い文書に現れる単語は、高頻度語とみなして削除する。\n",
    "* 30件未満の文書にしか現れない単語は、低頻度語とみなして削除する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "def download_stopwords(path):\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    if os.path.exists(path):\n",
    "        print('File already exists.')\n",
    "    else:\n",
    "        print('Downloading...')\n",
    "        # Download the file from `url` and save it locally under `file_name`:\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "\n",
    "def create_stopwords(file_path):\n",
    "    stop_words = []\n",
    "    for w in open(path, \"r\"):\n",
    "        w = w.replace('\\n','')\n",
    "        if len(w) > 0:\n",
    "          stop_words.append(w)\n",
    "    return stop_words    \n",
    "\n",
    "path = \"stop_words.txt\"\n",
    "download_stopwords(path)\n",
    "stop_words = create_stopwords(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zrj0mmMrCzNI"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "MIN_DF = 30\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.5, min_df= MIN_DF, stop_words=stop_words)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XoE0bBHJEFEj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2wVko9vXnlq"
   },
   "source": [
    "* 文書数と語彙サイズを変数にセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kAd821DGFXXp"
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG8puM9OXrNk"
   },
   "source": [
    "### TF-IDFで各文書における単語の重みを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ywX2HtW-Elar"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "Xtfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hdac5_tSE4YC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4227)\t0.603862693464167\n",
      "  (0, 4148)\t0.4706802938434637\n",
      "  (0, 3490)\t0.1847556021921528\n",
      "  (0, 3414)\t0.33418592758883475\n",
      "  (0, 3402)\t0.3582132311126842\n",
      "  (0, 1747)\t0.24047370992039763\n",
      "  (0, 1109)\t0.28609564411708244\n"
     ]
    }
   ],
   "source": [
    "print(Xtfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CY0mRZonFEJF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88481, 5100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXUdhYDMYuDO"
   },
   "source": [
    "### LDAのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5L34qQ1iFncJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from time import time\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPHsNjupYp7w"
   },
   "source": [
    "### トピックの重要語を取り出す関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rpoC-pofHMEO"
   },
   "outputs": [],
   "source": [
    "def get_top_words(model, feature_names, n_top_words=30):\n",
    "  top_features = list()\n",
    "  weights = list()\n",
    "  for topic_idx, topic in enumerate(model.components_):\n",
    "    top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    top_features.append([feature_names[i] for i in top_features_ind])\n",
    "    weights.append(topic[top_features_ind])\n",
    "  return top_features, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EHfuc6RZgPh"
   },
   "source": [
    "# LDAでトピック抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSAEThMwZjhb"
   },
   "source": [
    "### LDAによるトピック抽出の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NFf5jcX5b45d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_word_cloud(n_components, lda):\n",
    "    # matplotlib and seaborn for plotting\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    plt.style.use('dark_background')\n",
    "    top_words, weights = get_top_words(lda, vectorizer.get_feature_names())\n",
    "    topic_words = [dict(zip(top_words[i], weights[i])) for i in range(n_components)]\n",
    "    FONT_PATH = \"/usr/share/fonts/opentype/ipaexfont-mincho/ipaexm.ttf\"\n",
    "    cloud = WordCloud(stopwords=STOPWORDS,\n",
    "                  font_path=FONT_PATH,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=100,\n",
    "                  colormap='tab10'\n",
    "                  )\n",
    "\n",
    "    tate = math.ceil(len(topic_words) / 2)\n",
    "    fig, axes = plt.subplots(tate, 2, figsize=(32, 50), sharex=True, sharey=True)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "\n",
    "        if i >= len(topic_words):\n",
    "            break\n",
    "\n",
    "        fig.add_subplot(ax)\n",
    "        cloud.generate_from_frequencies(topic_words[i], max_font_size=500)\n",
    "        plt.gca().imshow(cloud)\n",
    "        plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "        plt.gca().axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pdf = PdfPages( \n",
    "        (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M') + 'topic.pdf')\n",
    "\n",
    "\n",
    "    fignums = plt.get_fignums()\n",
    "    for fignum in fignums:\n",
    "        plt.figure(fignum)\n",
    "        pdf.savefig()\n",
    "\n",
    "    pdf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KuuSTK6fZfu7"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "def lda_main (batch_size ,n_components, topic_word_prior,doc_topic_prior  ,max_iter=30):\n",
    "\n",
    "    folder_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M')\n",
    "\n",
    "    # フォルダを作成\n",
    "    os.mkdir(\"./0705expt_para/\"+folder_name)\n",
    "    os.chdir(\"./0705expt_para/\"+folder_name)\n",
    "\n",
    "    # logging\n",
    "    logger = logging.getLogger()\n",
    "    fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.setLevel(logging.WARNING)\n",
    "    \n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=n_components, \n",
    "                                    max_iter=max_iter,\n",
    "                                    topic_word_prior=topic_word_prior, # トピック数の逆数が目安の0.01,0.02,0.05,0.1などなど試す\n",
    "                                    doc_topic_prior =  doc_topic_prior, \n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50,\n",
    "                                    batch_size= batch_size,# 多くする\n",
    "#                                     learning_decay = 0.7,    \n",
    "                                    mean_change_tol=1e-4,\n",
    "                                    random_state=1,\n",
    "                                    evaluate_every=1,\n",
    "                                    verbose=1)\n",
    "    print((f\"Fitting LDA models with tf features, \"\n",
    "    f\"n_samples={n_samples} and n_features={n_features}\"))\n",
    "    t0 = time()\n",
    "    lda.fit(X)\n",
    "    print(f\"done in {time() - t0:0.3f}s.\")\n",
    "    # パラメータの比較はperplexity\n",
    "    # ハイパーパラメータ調整を頑張る！（やってられない！といわない！！）\n",
    "    \n",
    "    \n",
    "    coherance = metric_coherence_gensim(measure='c_v', \n",
    "#                         top_n=20, # これはデフォルトが20\n",
    "                        topic_word_distrib=lda.components_, \n",
    "                        dtm=Xtfidf,  # tfidfの結果\n",
    "                        vocab=np.array([x for x in vectorizer.vocabulary_.keys()]), \n",
    "                        texts=new_docs)\n",
    "    \n",
    "    \n",
    "    results = {\n",
    "            \"perplexity\" : lda.perplexity(X) ,\n",
    "            \"coherance\": coherance,\n",
    "        }\n",
    "\n",
    "    logger.warning('MIN_DF:{0}'.format(MIN_DF) )\n",
    "    logger.warning('params:batch_size:{0}'.format(batch_size)) \n",
    "    logger.warning('params:n_components:{0}'.format(n_components)) \n",
    "    logger.warning('params:topic_word_prior:{0}'.format(topic_word_prior)) \n",
    "    logger.warning('params:doc_topic_prior:{0}'.format(doc_topic_prior)) \n",
    "    logger.warning('params:max_iter:{0}'.format(max_iter)) \n",
    "    logger.warning('done n_iter:{0}'.format(lda.n_iter_)) \n",
    "    logger.warning('perplexity:{0}'.format(results[\"perplexity\"])) \n",
    "    logger.warning('coherance:{0}'.format(results[\"coherance\"]) )\n",
    "    logger.warning('check all params:{0}'.format(lda.get_params() )) \n",
    "    make_word_cloud(n_components, lda)\n",
    "    # pickle\n",
    "    file_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M') + '_lda.pickle'\n",
    "    with open(file_name, mode=\"wb\") as f:\n",
    "        pickle.dump(lda, f)\n",
    "    \n",
    "#     breakpoint()\n",
    "    \n",
    "    os.chdir(\"../../\")\n",
    "    return(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWd3DND8aAVz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 2011.4737\n",
      "iteration: 2 of max_iter: 50, perplexity: 1871.6366\n",
      "iteration: 3 of max_iter: 50, perplexity: 1827.8647\n",
      "iteration: 4 of max_iter: 50, perplexity: 1813.9337\n",
      "iteration: 5 of max_iter: 50, perplexity: 1808.3052\n",
      "iteration: 6 of max_iter: 50, perplexity: 1805.2524\n",
      "iteration: 7 of max_iter: 50, perplexity: 1803.6179\n",
      "iteration: 8 of max_iter: 50, perplexity: 1803.0518\n",
      "iteration: 9 of max_iter: 50, perplexity: 1802.4547\n",
      "iteration: 10 of max_iter: 50, perplexity: 1802.2666\n",
      "iteration: 11 of max_iter: 50, perplexity: 1801.8955\n",
      "iteration: 12 of max_iter: 50, perplexity: 1801.6630\n",
      "iteration: 13 of max_iter: 50, perplexity: 1801.5919\n",
      "done in 348.898s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1814.4494\n",
      "iteration: 2 of max_iter: 50, perplexity: 1675.1192\n",
      "iteration: 3 of max_iter: 50, perplexity: 1628.8591\n",
      "iteration: 4 of max_iter: 50, perplexity: 1610.1375\n",
      "iteration: 5 of max_iter: 50, perplexity: 1600.6587\n",
      "iteration: 6 of max_iter: 50, perplexity: 1595.3236\n",
      "iteration: 7 of max_iter: 50, perplexity: 1591.8622\n",
      "iteration: 8 of max_iter: 50, perplexity: 1589.5653\n",
      "iteration: 9 of max_iter: 50, perplexity: 1587.6440\n",
      "iteration: 10 of max_iter: 50, perplexity: 1586.1926\n",
      "iteration: 11 of max_iter: 50, perplexity: 1584.9425\n",
      "iteration: 12 of max_iter: 50, perplexity: 1584.0431\n",
      "iteration: 13 of max_iter: 50, perplexity: 1583.2981\n",
      "iteration: 14 of max_iter: 50, perplexity: 1582.6921\n",
      "iteration: 19 of max_iter: 50, perplexity: 1581.0272\n",
      "iteration: 20 of max_iter: 50, perplexity: 1580.8227\n",
      "iteration: 21 of max_iter: 50, perplexity: 1580.7166\n",
      "iteration: 22 of max_iter: 50, perplexity: 1580.4831\n",
      "iteration: 23 of max_iter: 50, perplexity: 1580.3714\n",
      "iteration: 24 of max_iter: 50, perplexity: 1580.2581\n",
      "iteration: 25 of max_iter: 50, perplexity: 1580.0924\n",
      "iteration: 26 of max_iter: 50, perplexity: 1580.0065\n",
      "done in 665.484s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1770.8396\n",
      "iteration: 2 of max_iter: 50, perplexity: 1625.2637\n",
      "iteration: 3 of max_iter: 50, perplexity: 1573.0798\n",
      "iteration: 4 of max_iter: 50, perplexity: 1550.2582\n",
      "iteration: 5 of max_iter: 50, perplexity: 1538.4509\n",
      "iteration: 6 of max_iter: 50, perplexity: 1531.5426\n",
      "iteration: 7 of max_iter: 50, perplexity: 1526.6949\n",
      "iteration: 8 of max_iter: 50, perplexity: 1523.4424\n",
      "iteration: 9 of max_iter: 50, perplexity: 1520.8793\n",
      "iteration: 10 of max_iter: 50, perplexity: 1518.9348\n",
      "iteration: 11 of max_iter: 50, perplexity: 1517.3352\n",
      "iteration: 12 of max_iter: 50, perplexity: 1516.1048\n",
      "iteration: 13 of max_iter: 50, perplexity: 1515.2419\n",
      "iteration: 14 of max_iter: 50, perplexity: 1514.5702\n",
      "iteration: 15 of max_iter: 50, perplexity: 1513.8637\n",
      "iteration: 16 of max_iter: 50, perplexity: 1513.3384\n",
      "iteration: 17 of max_iter: 50, perplexity: 1512.9407\n",
      "iteration: 18 of max_iter: 50, perplexity: 1512.4939\n",
      "iteration: 19 of max_iter: 50, perplexity: 1512.0532\n",
      "iteration: 20 of max_iter: 50, perplexity: 1511.6870\n",
      "iteration: 21 of max_iter: 50, perplexity: 1511.3539\n",
      "iteration: 22 of max_iter: 50, perplexity: 1511.0098\n",
      "iteration: 23 of max_iter: 50, perplexity: 1510.6785\n",
      "iteration: 24 of max_iter: 50, perplexity: 1510.4278\n",
      "iteration: 25 of max_iter: 50, perplexity: 1510.1208\n",
      "iteration: 26 of max_iter: 50, perplexity: 1509.8935\n",
      "iteration: 27 of max_iter: 50, perplexity: 1509.7448\n",
      "iteration: 28 of max_iter: 50, perplexity: 1509.5384\n",
      "iteration: 29 of max_iter: 50, perplexity: 1509.3656\n",
      "iteration: 30 of max_iter: 50, perplexity: 1509.1971\n",
      "iteration: 31 of max_iter: 50, perplexity: 1509.0510\n",
      "iteration: 32 of max_iter: 50, perplexity: 1508.9258\n",
      "iteration: 33 of max_iter: 50, perplexity: 1508.7785\n",
      "iteration: 34 of max_iter: 50, perplexity: 1508.6659\n",
      "iteration: 35 of max_iter: 50, perplexity: 1508.5305\n",
      "iteration: 36 of max_iter: 50, perplexity: 1508.4592\n",
      "done in 904.649s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1768.7942\n",
      "iteration: 2 of max_iter: 50, perplexity: 1597.5974\n",
      "iteration: 3 of max_iter: 50, perplexity: 1532.0089\n",
      "iteration: 4 of max_iter: 50, perplexity: 1501.0135\n",
      "iteration: 5 of max_iter: 50, perplexity: 1482.9696\n",
      "iteration: 6 of max_iter: 50, perplexity: 1471.1453\n",
      "iteration: 7 of max_iter: 50, perplexity: 1462.8985\n",
      "iteration: 8 of max_iter: 50, perplexity: 1456.8190\n",
      "iteration: 9 of max_iter: 50, perplexity: 1452.1404\n",
      "iteration: 10 of max_iter: 50, perplexity: 1448.5169\n",
      "iteration: 11 of max_iter: 50, perplexity: 1445.6056\n",
      "iteration: 12 of max_iter: 50, perplexity: 1443.2691\n",
      "iteration: 13 of max_iter: 50, perplexity: 1441.3396\n",
      "iteration: 14 of max_iter: 50, perplexity: 1439.7449\n",
      "iteration: 15 of max_iter: 50, perplexity: 1438.4253\n",
      "iteration: 16 of max_iter: 50, perplexity: 1437.2524\n",
      "iteration: 17 of max_iter: 50, perplexity: 1436.1944\n",
      "iteration: 18 of max_iter: 50, perplexity: 1435.2491\n",
      "iteration: 19 of max_iter: 50, perplexity: 1434.3671\n",
      "iteration: 20 of max_iter: 50, perplexity: 1433.5632\n",
      "iteration: 25 of max_iter: 50, perplexity: 1430.6509\n",
      "iteration: 26 of max_iter: 50, perplexity: 1430.2178\n",
      "iteration: 27 of max_iter: 50, perplexity: 1429.7994\n",
      "iteration: 28 of max_iter: 50, perplexity: 1429.4303\n",
      "iteration: 29 of max_iter: 50, perplexity: 1429.1110\n",
      "iteration: 30 of max_iter: 50, perplexity: 1428.7852\n",
      "iteration: 31 of max_iter: 50, perplexity: 1428.5110\n",
      "iteration: 32 of max_iter: 50, perplexity: 1428.2394\n",
      "iteration: 33 of max_iter: 50, perplexity: 1427.9810\n",
      "iteration: 34 of max_iter: 50, perplexity: 1427.7269\n",
      "iteration: 35 of max_iter: 50, perplexity: 1427.5043\n",
      "iteration: 36 of max_iter: 50, perplexity: 1427.2870\n",
      "iteration: 37 of max_iter: 50, perplexity: 1427.0741\n",
      "iteration: 38 of max_iter: 50, perplexity: 1426.8786\n",
      "iteration: 39 of max_iter: 50, perplexity: 1426.7083\n",
      "iteration: 40 of max_iter: 50, perplexity: 1426.5293\n",
      "iteration: 41 of max_iter: 50, perplexity: 1426.3479\n",
      "iteration: 42 of max_iter: 50, perplexity: 1426.1998\n",
      "iteration: 43 of max_iter: 50, perplexity: 1426.0476\n",
      "iteration: 44 of max_iter: 50, perplexity: 1425.9142\n",
      "iteration: 45 of max_iter: 50, perplexity: 1425.7749\n",
      "iteration: 46 of max_iter: 50, perplexity: 1425.6527\n",
      "iteration: 47 of max_iter: 50, perplexity: 1425.5409\n",
      "iteration: 48 of max_iter: 50, perplexity: 1425.4282\n",
      "iteration: 49 of max_iter: 50, perplexity: 1425.3226\n",
      "iteration: 50 of max_iter: 50, perplexity: 1425.2149\n",
      "done in 1248.996s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1852.0368\n",
      "iteration: 2 of max_iter: 50, perplexity: 1658.6851\n",
      "iteration: 3 of max_iter: 50, perplexity: 1580.1331\n",
      "iteration: 4 of max_iter: 50, perplexity: 1541.5197\n",
      "iteration: 5 of max_iter: 50, perplexity: 1518.8630\n",
      "iteration: 6 of max_iter: 50, perplexity: 1503.7861\n",
      "iteration: 7 of max_iter: 50, perplexity: 1492.9560\n",
      "iteration: 8 of max_iter: 50, perplexity: 1484.6069\n",
      "iteration: 9 of max_iter: 50, perplexity: 1478.1286\n",
      "iteration: 10 of max_iter: 50, perplexity: 1472.9751\n",
      "iteration: 11 of max_iter: 50, perplexity: 1468.8254\n",
      "iteration: 12 of max_iter: 50, perplexity: 1465.4064\n",
      "iteration: 13 of max_iter: 50, perplexity: 1462.4937\n",
      "iteration: 14 of max_iter: 50, perplexity: 1459.9256\n",
      "iteration: 15 of max_iter: 50, perplexity: 1457.7099\n",
      "iteration: 16 of max_iter: 50, perplexity: 1455.7786\n",
      "iteration: 17 of max_iter: 50, perplexity: 1454.0793\n",
      "iteration: 18 of max_iter: 50, perplexity: 1452.5834\n",
      "iteration: 19 of max_iter: 50, perplexity: 1451.2598\n",
      "iteration: 20 of max_iter: 50, perplexity: 1450.0691\n",
      "iteration: 21 of max_iter: 50, perplexity: 1448.9920\n",
      "iteration: 22 of max_iter: 50, perplexity: 1448.0087\n",
      "iteration: 23 of max_iter: 50, perplexity: 1447.1129\n",
      "iteration: 24 of max_iter: 50, perplexity: 1446.3021\n",
      "iteration: 25 of max_iter: 50, perplexity: 1445.5571\n",
      "iteration: 26 of max_iter: 50, perplexity: 1444.8769\n",
      "iteration: 27 of max_iter: 50, perplexity: 1444.2466\n",
      "iteration: 28 of max_iter: 50, perplexity: 1443.6628\n",
      "iteration: 29 of max_iter: 50, perplexity: 1443.1234\n",
      "iteration: 30 of max_iter: 50, perplexity: 1442.6219\n",
      "iteration: 31 of max_iter: 50, perplexity: 1442.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 32 of max_iter: 50, perplexity: 1441.7199\n",
      "iteration: 33 of max_iter: 50, perplexity: 1441.3058\n",
      "iteration: 34 of max_iter: 50, perplexity: 1440.9096\n",
      "iteration: 35 of max_iter: 50, perplexity: 1440.5360\n",
      "iteration: 36 of max_iter: 50, perplexity: 1440.1847\n",
      "iteration: 37 of max_iter: 50, perplexity: 1439.8529\n",
      "iteration: 38 of max_iter: 50, perplexity: 1439.5409\n",
      "iteration: 43 of max_iter: 50, perplexity: 1438.2066\n",
      "iteration: 44 of max_iter: 50, perplexity: 1437.9756\n",
      "iteration: 45 of max_iter: 50, perplexity: 1437.7539\n",
      "iteration: 46 of max_iter: 50, perplexity: 1437.5407\n",
      "iteration: 47 of max_iter: 50, perplexity: 1437.3370\n",
      "iteration: 48 of max_iter: 50, perplexity: 1437.1421\n",
      "iteration: 49 of max_iter: 50, perplexity: 1436.9550\n",
      "iteration: 50 of max_iter: 50, perplexity: 1436.7747\n",
      "done in 1349.453s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1852.9846\n",
      "iteration: 2 of max_iter: 50, perplexity: 1655.4379\n",
      "iteration: 3 of max_iter: 50, perplexity: 1569.8829\n",
      "iteration: 4 of max_iter: 50, perplexity: 1526.7843\n",
      "iteration: 5 of max_iter: 50, perplexity: 1501.3265\n",
      "iteration: 6 of max_iter: 50, perplexity: 1484.5263\n",
      "iteration: 7 of max_iter: 50, perplexity: 1472.4980\n",
      "iteration: 8 of max_iter: 50, perplexity: 1463.4308\n",
      "iteration: 9 of max_iter: 50, perplexity: 1456.3099\n",
      "iteration: 10 of max_iter: 50, perplexity: 1450.5992\n",
      "iteration: 11 of max_iter: 50, perplexity: 1445.9256\n",
      "iteration: 12 of max_iter: 50, perplexity: 1442.0524\n",
      "iteration: 13 of max_iter: 50, perplexity: 1438.7970\n",
      "iteration: 14 of max_iter: 50, perplexity: 1436.0260\n",
      "iteration: 15 of max_iter: 50, perplexity: 1433.6272\n",
      "iteration: 16 of max_iter: 50, perplexity: 1431.5450\n",
      "iteration: 17 of max_iter: 50, perplexity: 1429.7207\n",
      "iteration: 18 of max_iter: 50, perplexity: 1428.0995\n",
      "iteration: 19 of max_iter: 50, perplexity: 1426.6422\n",
      "iteration: 20 of max_iter: 50, perplexity: 1425.3150\n",
      "iteration: 21 of max_iter: 50, perplexity: 1424.1009\n",
      "iteration: 22 of max_iter: 50, perplexity: 1422.9898\n",
      "iteration: 23 of max_iter: 50, perplexity: 1421.9644\n",
      "iteration: 24 of max_iter: 50, perplexity: 1421.0265\n",
      "iteration: 25 of max_iter: 50, perplexity: 1420.1692\n",
      "iteration: 26 of max_iter: 50, perplexity: 1419.3825\n",
      "iteration: 27 of max_iter: 50, perplexity: 1418.6563\n",
      "iteration: 28 of max_iter: 50, perplexity: 1417.9848\n",
      "iteration: 29 of max_iter: 50, perplexity: 1417.3625\n",
      "iteration: 30 of max_iter: 50, perplexity: 1416.7831\n",
      "iteration: 31 of max_iter: 50, perplexity: 1416.2412\n",
      "iteration: 32 of max_iter: 50, perplexity: 1415.7336\n",
      "iteration: 33 of max_iter: 50, perplexity: 1415.2566\n",
      "iteration: 34 of max_iter: 50, perplexity: 1414.8067\n",
      "iteration: 35 of max_iter: 50, perplexity: 1414.3809\n",
      "iteration: 36 of max_iter: 50, perplexity: 1413.9760\n",
      "iteration: 37 of max_iter: 50, perplexity: 1413.5915\n",
      "iteration: 38 of max_iter: 50, perplexity: 1413.2268\n",
      "iteration: 39 of max_iter: 50, perplexity: 1412.8795\n",
      "iteration: 40 of max_iter: 50, perplexity: 1412.5489\n",
      "iteration: 41 of max_iter: 50, perplexity: 1412.2344\n",
      "iteration: 42 of max_iter: 50, perplexity: 1411.9346\n",
      "iteration: 43 of max_iter: 50, perplexity: 1411.6485\n",
      "iteration: 44 of max_iter: 50, perplexity: 1411.3748\n",
      "iteration: 45 of max_iter: 50, perplexity: 1411.1116\n",
      "iteration: 46 of max_iter: 50, perplexity: 1410.8579\n",
      "iteration: 47 of max_iter: 50, perplexity: 1410.6139\n",
      "iteration: 48 of max_iter: 50, perplexity: 1410.3799\n",
      "iteration: 49 of max_iter: 50, perplexity: 1410.1551\n",
      "iteration: 50 of max_iter: 50, perplexity: 1409.9384\n",
      "done in 1201.334s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1852.1897\n",
      "iteration: 2 of max_iter: 50, perplexity: 1655.1073\n",
      "iteration: 3 of max_iter: 50, perplexity: 1563.9316\n",
      "iteration: 4 of max_iter: 50, perplexity: 1516.0819\n",
      "iteration: 5 of max_iter: 50, perplexity: 1487.4316\n",
      "iteration: 6 of max_iter: 50, perplexity: 1468.3107\n",
      "iteration: 7 of max_iter: 50, perplexity: 1454.6015\n",
      "iteration: 8 of max_iter: 50, perplexity: 1444.2923\n",
      "iteration: 13 of max_iter: 50, perplexity: 1416.5772\n",
      "iteration: 14 of max_iter: 50, perplexity: 1413.3878\n",
      "iteration: 15 of max_iter: 50, perplexity: 1410.6231\n",
      "iteration: 16 of max_iter: 50, perplexity: 1408.2020\n",
      "iteration: 17 of max_iter: 50, perplexity: 1406.0681\n",
      "iteration: 18 of max_iter: 50, perplexity: 1404.1763\n",
      "iteration: 19 of max_iter: 50, perplexity: 1402.4881\n",
      "iteration: 20 of max_iter: 50, perplexity: 1400.9719\n",
      "iteration: 21 of max_iter: 50, perplexity: 1399.5999\n",
      "iteration: 22 of max_iter: 50, perplexity: 1398.3532\n",
      "iteration: 23 of max_iter: 50, perplexity: 1397.2168\n",
      "iteration: 24 of max_iter: 50, perplexity: 1396.1768\n",
      "iteration: 25 of max_iter: 50, perplexity: 1395.2209\n",
      "iteration: 26 of max_iter: 50, perplexity: 1394.3403\n",
      "iteration: 27 of max_iter: 50, perplexity: 1393.5265\n",
      "iteration: 28 of max_iter: 50, perplexity: 1392.7723\n",
      "iteration: 29 of max_iter: 50, perplexity: 1392.0712\n",
      "iteration: 30 of max_iter: 50, perplexity: 1391.4169\n",
      "iteration: 31 of max_iter: 50, perplexity: 1390.8043\n",
      "iteration: 32 of max_iter: 50, perplexity: 1390.2292\n",
      "iteration: 33 of max_iter: 50, perplexity: 1389.6884\n",
      "iteration: 34 of max_iter: 50, perplexity: 1389.1782\n",
      "iteration: 35 of max_iter: 50, perplexity: 1388.6946\n",
      "iteration: 36 of max_iter: 50, perplexity: 1388.2347\n",
      "iteration: 37 of max_iter: 50, perplexity: 1387.7965\n",
      "iteration: 38 of max_iter: 50, perplexity: 1387.3799\n",
      "iteration: 39 of max_iter: 50, perplexity: 1386.9849\n",
      "iteration: 40 of max_iter: 50, perplexity: 1386.6109\n",
      "iteration: 41 of max_iter: 50, perplexity: 1386.2567\n",
      "iteration: 42 of max_iter: 50, perplexity: 1385.9210\n",
      "iteration: 43 of max_iter: 50, perplexity: 1385.6025\n",
      "iteration: 44 of max_iter: 50, perplexity: 1385.3000\n",
      "iteration: 45 of max_iter: 50, perplexity: 1385.0122\n",
      "iteration: 46 of max_iter: 50, perplexity: 1384.7381\n",
      "iteration: 47 of max_iter: 50, perplexity: 1384.4768\n",
      "iteration: 48 of max_iter: 50, perplexity: 1384.2272\n",
      "iteration: 49 of max_iter: 50, perplexity: 1383.9887\n",
      "iteration: 50 of max_iter: 50, perplexity: 1383.7604\n",
      "done in 1282.083s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1845.4817\n",
      "iteration: 2 of max_iter: 50, perplexity: 1644.0327\n",
      "iteration: 3 of max_iter: 50, perplexity: 1548.2746\n",
      "iteration: 4 of max_iter: 50, perplexity: 1497.4842\n",
      "iteration: 5 of max_iter: 50, perplexity: 1467.8671\n",
      "iteration: 6 of max_iter: 50, perplexity: 1448.9041\n",
      "iteration: 7 of max_iter: 50, perplexity: 1435.7905\n",
      "iteration: 8 of max_iter: 50, perplexity: 1426.1530\n",
      "iteration: 9 of max_iter: 50, perplexity: 1418.7361\n",
      "iteration: 10 of max_iter: 50, perplexity: 1412.8269\n",
      "iteration: 11 of max_iter: 50, perplexity: 1408.0037\n",
      "iteration: 12 of max_iter: 50, perplexity: 1403.9941\n",
      "iteration: 13 of max_iter: 50, perplexity: 1400.6026\n",
      "iteration: 14 of max_iter: 50, perplexity: 1397.6891\n",
      "iteration: 15 of max_iter: 50, perplexity: 1395.1558\n",
      "iteration: 16 of max_iter: 50, perplexity: 1392.9323\n",
      "iteration: 17 of max_iter: 50, perplexity: 1390.9684\n",
      "iteration: 18 of max_iter: 50, perplexity: 1389.2265\n",
      "iteration: 19 of max_iter: 50, perplexity: 1387.6728\n",
      "iteration: 20 of max_iter: 50, perplexity: 1386.2783\n",
      "iteration: 21 of max_iter: 50, perplexity: 1385.0201\n",
      "iteration: 22 of max_iter: 50, perplexity: 1383.8785\n",
      "iteration: 23 of max_iter: 50, perplexity: 1382.8371\n",
      "iteration: 24 of max_iter: 50, perplexity: 1381.8832\n",
      "iteration: 25 of max_iter: 50, perplexity: 1381.0065\n",
      "iteration: 26 of max_iter: 50, perplexity: 1380.1980\n",
      "iteration: 32 of max_iter: 50, perplexity: 1376.4017\n",
      "iteration: 33 of max_iter: 50, perplexity: 1375.8993\n",
      "iteration: 34 of max_iter: 50, perplexity: 1375.4253\n",
      "iteration: 35 of max_iter: 50, perplexity: 1374.9777\n",
      "iteration: 36 of max_iter: 50, perplexity: 1374.5543\n",
      "iteration: 37 of max_iter: 50, perplexity: 1374.1532\n",
      "iteration: 38 of max_iter: 50, perplexity: 1373.7727\n",
      "iteration: 39 of max_iter: 50, perplexity: 1373.4110\n",
      "iteration: 40 of max_iter: 50, perplexity: 1373.0665\n",
      "iteration: 41 of max_iter: 50, perplexity: 1372.7379\n",
      "iteration: 42 of max_iter: 50, perplexity: 1372.4240\n",
      "iteration: 43 of max_iter: 50, perplexity: 1372.1236\n",
      "iteration: 44 of max_iter: 50, perplexity: 1371.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 45 of max_iter: 50, perplexity: 1371.5592\n",
      "iteration: 46 of max_iter: 50, perplexity: 1371.2938\n",
      "iteration: 47 of max_iter: 50, perplexity: 1371.0385\n",
      "iteration: 48 of max_iter: 50, perplexity: 1370.7928\n",
      "iteration: 49 of max_iter: 50, perplexity: 1370.5562\n",
      "iteration: 50 of max_iter: 50, perplexity: 1370.3279\n",
      "done in 1163.029s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1978.8590\n",
      "iteration: 2 of max_iter: 50, perplexity: 1729.4169\n",
      "iteration: 3 of max_iter: 50, perplexity: 1607.1308\n",
      "iteration: 4 of max_iter: 50, perplexity: 1537.0350\n",
      "iteration: 5 of max_iter: 50, perplexity: 1494.4099\n",
      "iteration: 6 of max_iter: 50, perplexity: 1466.7647\n",
      "iteration: 7 of max_iter: 50, perplexity: 1447.6754\n",
      "iteration: 8 of max_iter: 50, perplexity: 1433.7517\n",
      "iteration: 9 of max_iter: 50, perplexity: 1423.0889\n",
      "iteration: 10 of max_iter: 50, perplexity: 1414.6562\n",
      "iteration: 11 of max_iter: 50, perplexity: 1407.8928\n",
      "iteration: 12 of max_iter: 50, perplexity: 1402.3967\n",
      "iteration: 13 of max_iter: 50, perplexity: 1397.8469\n",
      "iteration: 14 of max_iter: 50, perplexity: 1394.0149\n",
      "iteration: 15 of max_iter: 50, perplexity: 1390.7425\n",
      "iteration: 16 of max_iter: 50, perplexity: 1387.9149\n",
      "iteration: 17 of max_iter: 50, perplexity: 1385.4445\n",
      "iteration: 18 of max_iter: 50, perplexity: 1383.2637\n",
      "iteration: 19 of max_iter: 50, perplexity: 1381.3216\n",
      "iteration: 20 of max_iter: 50, perplexity: 1379.5794\n",
      "iteration: 21 of max_iter: 50, perplexity: 1378.0058\n",
      "iteration: 22 of max_iter: 50, perplexity: 1376.5751\n",
      "iteration: 23 of max_iter: 50, perplexity: 1375.2662\n",
      "iteration: 24 of max_iter: 50, perplexity: 1374.0620\n",
      "iteration: 25 of max_iter: 50, perplexity: 1372.9494\n",
      "iteration: 26 of max_iter: 50, perplexity: 1371.9183\n",
      "iteration: 27 of max_iter: 50, perplexity: 1370.9609\n",
      "iteration: 28 of max_iter: 50, perplexity: 1370.0710\n",
      "iteration: 29 of max_iter: 50, perplexity: 1369.2431\n",
      "iteration: 30 of max_iter: 50, perplexity: 1368.4714\n",
      "iteration: 31 of max_iter: 50, perplexity: 1367.7500\n",
      "iteration: 32 of max_iter: 50, perplexity: 1367.0735\n",
      "iteration: 33 of max_iter: 50, perplexity: 1366.4372\n",
      "iteration: 34 of max_iter: 50, perplexity: 1365.8369\n",
      "iteration: 35 of max_iter: 50, perplexity: 1365.2695\n",
      "iteration: 36 of max_iter: 50, perplexity: 1364.7322\n",
      "iteration: 37 of max_iter: 50, perplexity: 1364.2227\n",
      "iteration: 38 of max_iter: 50, perplexity: 1363.7388\n",
      "iteration: 39 of max_iter: 50, perplexity: 1363.2786\n",
      "iteration: 40 of max_iter: 50, perplexity: 1362.8403\n",
      "iteration: 41 of max_iter: 50, perplexity: 1362.4223\n",
      "iteration: 42 of max_iter: 50, perplexity: 1362.0231\n",
      "iteration: 43 of max_iter: 50, perplexity: 1361.6414\n",
      "iteration: 44 of max_iter: 50, perplexity: 1361.2758\n",
      "iteration: 45 of max_iter: 50, perplexity: 1360.9254\n",
      "iteration: 46 of max_iter: 50, perplexity: 1360.5893\n",
      "iteration: 47 of max_iter: 50, perplexity: 1360.2665\n",
      "iteration: 48 of max_iter: 50, perplexity: 1359.9563\n",
      "iteration: 49 of max_iter: 50, perplexity: 1359.6578\n",
      "iteration: 50 of max_iter: 50, perplexity: 1359.3704\n",
      "done in 975.306s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1905.9918\n",
      "iteration: 2 of max_iter: 50, perplexity: 1805.1427\n",
      "iteration: 3 of max_iter: 50, perplexity: 1780.1591\n",
      "iteration: 4 of max_iter: 50, perplexity: 1772.9075\n",
      "iteration: 5 of max_iter: 50, perplexity: 1770.3519\n",
      "iteration: 6 of max_iter: 50, perplexity: 1769.9491\n",
      "iteration: 7 of max_iter: 50, perplexity: 1769.7080\n",
      "iteration: 8 of max_iter: 50, perplexity: 1769.9048\n",
      "iteration: 9 of max_iter: 50, perplexity: 1770.4427\n",
      "iteration: 10 of max_iter: 50, perplexity: 1771.1555\n",
      "iteration: 11 of max_iter: 50, perplexity: 1771.4208\n",
      "iteration: 12 of max_iter: 50, perplexity: 1772.1131\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1723.7026\n",
      "iteration: 2 of max_iter: 50, perplexity: 1621.5741\n",
      "iteration: 3 of max_iter: 50, perplexity: 1591.5085\n",
      "iteration: 4 of max_iter: 50, perplexity: 1578.5300\n",
      "iteration: 5 of max_iter: 50, perplexity: 1571.6840\n",
      "iteration: 6 of max_iter: 50, perplexity: 1567.5841\n",
      "iteration: 7 of max_iter: 50, perplexity: 1565.0267\n",
      "iteration: 8 of max_iter: 50, perplexity: 1563.2849\n",
      "iteration: 9 of max_iter: 50, perplexity: 1561.9314\n",
      "iteration: 10 of max_iter: 50, perplexity: 1560.9167\n",
      "iteration: 11 of max_iter: 50, perplexity: 1560.3783\n",
      "iteration: 12 of max_iter: 50, perplexity: 1559.8531\n",
      "iteration: 13 of max_iter: 50, perplexity: 1559.5432\n",
      "iteration: 14 of max_iter: 50, perplexity: 1559.2729\n",
      "iteration: 15 of max_iter: 50, perplexity: 1559.1978\n",
      "done in 404.348s.\n",
      "Fitting LDA models with tf features, n_samples=88481 and n_features=5100\n",
      "iteration: 1 of max_iter: 50, perplexity: 1682.6295\n",
      "iteration: 2 of max_iter: 50, perplexity: 1573.8362\n",
      "iteration: 3 of max_iter: 50, perplexity: 1537.5474\n",
      "iteration: 4 of max_iter: 50, perplexity: 1521.5800\n",
      "iteration: 5 of max_iter: 50, perplexity: 1513.1045\n",
      "iteration: 6 of max_iter: 50, perplexity: 1508.0477\n",
      "iteration: 7 of max_iter: 50, perplexity: 1504.6700\n",
      "iteration: 8 of max_iter: 50, perplexity: 1502.3926\n",
      "iteration: 9 of max_iter: 50, perplexity: 1500.6758\n",
      "iteration: 10 of max_iter: 50, perplexity: 1499.3024\n",
      "iteration: 11 of max_iter: 50, perplexity: 1498.2513\n",
      "iteration: 12 of max_iter: 50, perplexity: 1497.4982\n",
      "iteration: 13 of max_iter: 50, perplexity: 1496.9408\n",
      "iteration: 14 of max_iter: 50, perplexity: 1496.3569\n",
      "iteration: 15 of max_iter: 50, perplexity: 1495.8823\n",
      "iteration: 16 of max_iter: 50, perplexity: 1495.4136\n",
      "iteration: 17 of max_iter: 50, perplexity: 1494.8924\n",
      "iteration: 18 of max_iter: 50, perplexity: 1494.5374\n"
     ]
    }
   ],
   "source": [
    "for batch_size,n_components, topic_word_prior, doc_topic_prior in itertools.product([1500,2500] ,[10,12,15,18,22,25,30,35,40,6,8],\n",
    "                                                                                    [0.01, 0.03,0.05, 0.15, 0.3, 0.4, 0.5, 0.6, 0.8],[0.01, 0.03,0.05, 0.15, 0.3, 0.4, 0.5, 0.6, 0.8] ):\n",
    "\n",
    "    lda_main(n_components=n_components, topic_word_prior=topic_word_prior, doc_topic_prior = doc_topic_prior, batch_size=batch_size, max_iter=50)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pez5Ak2-cUjS"
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_HRjNZJcbNr"
   },
   "source": [
    "### プロフィールを"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_prof (topic_idx, top_n = 100):\n",
    "    \n",
    "    topics = lda.transform(X)\n",
    "    prof_idx_list = topics[:, topic_idx].argsort()[:-top_n - 1:-1]\n",
    "    return [docs[d] for d in prof_idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_top_prof(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_top_prof(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nownow_file = (datetime.datetime.now() + datetime.timedelta(hours=9) ).strftime('%m%d_%H%M')+\"topic_modeling.ipynb\"\n",
    "\n",
    "!cp ./topic_modeling.ipynb ./jupyter_backup_for_param/$nownow_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = (datetime.datetime.now() + datetime.timedelta(hours=9) ) .strftime('%m%d_%H%M')+\"_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNyVTNTZxoqrFDwo2+taBP8",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "12MxXsGfePft6pAHKkHrg23Yb7t_RSKiN",
   "name": "11_topic_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
